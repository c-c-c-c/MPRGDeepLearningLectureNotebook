{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "11_augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJU2RPpSvlQT"
      },
      "source": [
        "# 11：データ拡張（Data Augmentation）\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "PyTorchを用いてMNIST Datasetに対する文字認識を行う．\n",
        "\n",
        "また，データ拡張（Data Augmentation）による効果を確認する．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### Google Colaboratoryの設定確認・変更\n",
        "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
        "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4jjpmwvle1"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCeaCulfvlao"
      },
      "source": [
        "# モジュールのインポート\n",
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import gzip\n",
        "from random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nbdiIyZId5i"
      },
      "source": [
        "## データセットのダウンロードと読み込みと学習サンプルの削減\n",
        "\n",
        "\n",
        "まずはじめに，`wget`コマンドを使用して，MNISTデータセットをダウンロードします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1LbRsqxIfoF"
      },
      "source": [
        "!wget -q http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz -O train-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz -O train-labels-idx1-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz -O t10k-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz -O t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5R2ghpzIqyf"
      },
      "source": [
        "次に，ダウンロードしたファイルからデータを読み込みます．詳細は前回までのプログラムを確認してください．\n",
        "\n",
        "今回は2次元の画像データとしてMNISTデータセットを扱うため，\n",
        "データを`(チャンネル, 縦，横)`の形に並べ替えます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlChw880IqDC"
      },
      "source": [
        "# load images\n",
        "with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n",
        "    x_train = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "\n",
        "with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
        "    x_test = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n",
        "    y_train = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
        "    y_test = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "x_train = x_train.reshape(-1, 1, 28, 28)\n",
        "x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## ネットワークモデルの定義\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ネットワークの定義は前回と同様のため，詳細は割愛します．\n",
        "詳しくは前回の資料を確認してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_channels=1, filter_size=3, num_kernel=64, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(n_channels, num_kernel, kernel_size=filter_size, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(int(28/2) * int(28/2) * num_kernel, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.relu(self.conv(x))\n",
        "        h = self.pool(h)\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.l2(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sQIb18bPZZi"
      },
      "source": [
        "## Data Augmentationの準備\n",
        "\n",
        "学習に使用する画像データに変換やノイズを加えるための関数を準備します．\n",
        "ここでは，ガウシアンノイズをランダムに適用する関数を作成します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD99U2NrPZfW"
      },
      "source": [
        "def data_augmentation(input_image):\n",
        "    bs, ch, h, w = input_image.shape\n",
        "    dst_image = input_image.copy()\n",
        "    for batch_index in range(bs):\n",
        "        augmentation_index = np.random.randint(0, 4, 1)[0]\n",
        "        if augmentation_index == 0:    # agumentationなし\n",
        "            continue\n",
        "        else:  # ガウシアンノイズ\n",
        "            noise = input_image[batch_index] + np.random.normal(0, 50, (1, 28, 28))\n",
        "            noise = np.clip(noise, 0, 255)\n",
        "            dst_image[batch_index, :] = noise\n",
        "    return dst_image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6RLSzr3PZl2"
      },
      "source": [
        "Data Augmentationを適用した結果を確認します．\n",
        "この結果を見ると，ランダムに画像が変換されていることが確認できます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phYoYXswPZr_"
      },
      "source": [
        "image = x_train[0:10].copy()\n",
        "aug_image = data_augmentation(image.astype(np.float32))\n",
        "\n",
        "# 元画像\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(14, 1.4))\n",
        "for i in range(image.shape[0]):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    img = image[i].transpose(1, 2, 0)\n",
        "    plt.imshow(img.astype(np.uint8)[:, :, 0], cmap=plt.cm.gray)\n",
        "    ax.set_axis_off()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Data Augmentationを適用した画像\n",
        "plt.clf()\n",
        "fig = plt.figure(figsize=(14, 1.4))\n",
        "for i in range(image.shape[0]):\n",
        "    ax = fig.add_subplot(1, 10, i + 1)\n",
        "    img = aug_image[i].transpose(1, 2, 0)\n",
        "    plt.imshow(img.astype(np.uint8)[:, :, 0], cmap=plt.cm.gray)\n",
        "    ax.set_axis_off()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dwuvfouzmd7"
      },
      "source": [
        "## ネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（use_cuda == True）には，ネットワークモデルをGPUメモリ上に配置します． これにより，GPUを用いた演算が可能となります．\n",
        "\n",
        "学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します． また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n",
        "\n",
        "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23m79Eq-zmjl"
      },
      "source": [
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "## 学習\n",
        "読み込んだMNISTデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "ここでは，ランダムに選択したミニバッチデータ`x_train`に対して，上で定義した`data_augmentation`関数を適用することで，ランダムにノイズを付加します．\n",
        "このデータを用いて学習を行うことで，毎回画像を変換しながら学習を行います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68RE3RTa76-W"
      },
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "num_train_data = x_train.shape[0]\n",
        "n_iter = num_train_data / batch_size\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "iteration = 1\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    perm = np.random.permutation(num_train_data)\n",
        "    for i in range(0, num_train_data, batch_size):\n",
        "        x_batch = x_train[perm[i:i+batch_size]]\n",
        "        y_batch = y_train[perm[i:i+batch_size]]\n",
        "\n",
        "        x_batch = data_augmentation(x_batch)\n",
        "\n",
        "        x_batch = torch.from_numpy(x_batch).type(torch.float32)\n",
        "        y_batch = torch.from_numpy(y_batch).type(torch.int64)\n",
        "\n",
        "        if use_cuda:\n",
        "            x_batch = x_batch.cuda()\n",
        "            y_batch = y_batch.cuda()\n",
        "\n",
        "        y = model(x_batch)\n",
        "\n",
        "        loss = criterion(y, y_batch)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == y_batch)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / num_train_data,\n",
        "                                                                                 time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価を行います．\n",
        "プログラムは前回までと同様のため，詳細は以前の資料を確認してください．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYVMRGLzm1I"
      },
      "source": [
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "num_test_data = x_test.shape[0]\n",
        "\n",
        "# 勾配計算なしで順伝播計算を行うためのフラグ\n",
        "with torch.no_grad():\n",
        "    for i in range(num_test_data):\n",
        "        x = np.array([x_test[i]], dtype=np.float32)\n",
        "        t = y_test[i]\n",
        "\n",
        "        x = torch.from_numpy(x).type(torch.float32)\n",
        "\n",
        "        if use_cuda:\n",
        "            x = x.cuda()\n",
        "\n",
        "        y = model.forward(x)\n",
        "        pred = torch.argmax(y)\n",
        "        \n",
        "        if pred == t:\n",
        "            count += 1\n",
        "\n",
        "print(\"test accuracy: {}\".format(count / num_test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzl4N5rC4j5u"
      },
      "source": [
        "## 課題\n",
        "1. ネットワーク構造を変えて実験しましょう． \n",
        "     * まず，1層目の畳み込み層のフィルタ数を32にしましょう．また，2層目の畳み込み層のフィルタ数を64にしましょう．\n",
        "    * 次に，中間層のユニット数を2048にしましょう．\n",
        "   \n",
        "\n",
        "\n",
        "2. 最適化の方法をAdamに変えて実験しましょう．\n",
        "\n",
        "\n",
        "\n",
        "3. エポック数やミニバッチサイズを変えて実験しましょう．\n",
        "    * まず，ミニバッチサイズを128にしましょう．\n",
        "    * 次に，エポック数を50にしましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjS-WptIg9Pf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
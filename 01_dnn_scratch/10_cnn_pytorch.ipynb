{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "10_cnn_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJU2RPpSvlQT"
      },
      "source": [
        "# 10：PyTorchを用いたCNNによる画像認識\n",
        "\n",
        "\n",
        "---\n",
        "## 目的\n",
        "PyTorchを用いてMNIST Datasetに対する文字認識を行う．\n",
        "\n",
        "また，ここではGPUを用いたネットワークの計算を行う．\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rQGfxWYK_4O"
      },
      "source": [
        "## 準備\n",
        "\n",
        "### Google Colaboratoryの設定確認・変更\n",
        "本チュートリアルではPyTorchを利用してニューラルネットワークの実装を確認，学習および評価を行います．\n",
        "**GPUを用いて処理を行うために，上部のメニューバーの「ランタイム」→「ランタイムのタイプを変更」からハードウェアアクセラレータをGPUにしてください．**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo4jjpmwvle1"
      },
      "source": [
        "## モジュールのインポート\n",
        "はじめに必要なモジュールをインポートする．\n",
        "\n",
        "### GPUの確認\n",
        "GPUを使用した計算が可能かどうかを確認します．\n",
        "\n",
        "`GPU availability: True`と表示されれば，GPUを使用した計算をPyTorchで行うことが可能です．\n",
        "Falseとなっている場合は，上記の「Google Colaboratoryの設定確認・変更」に記載している手順にしたがって，設定を変更した後に，モジュールのインポートから始めてください．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCeaCulfvlao"
      },
      "source": [
        "# モジュールのインポート\n",
        "import os\n",
        "from time import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torchsummary\n",
        "\n",
        "import gzip\n",
        "from random import randint\n",
        "\n",
        "# GPUの確認\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use CUDA:', use_cuda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nbdiIyZId5i"
      },
      "source": [
        "## データセットのダウンロードと読み込みと学習サンプルの削減\n",
        "\n",
        "\n",
        "まずはじめに，`wget`コマンドを使用して，MNISTデータセットをダウンロードします．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1LbRsqxIfoF"
      },
      "source": [
        "!wget -q http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz -O train-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz -O train-labels-idx1-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz -O t10k-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz -O t10k-labels-idx1-ubyte.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5R2ghpzIqyf"
      },
      "source": [
        "次に，ダウンロードしたファイルからデータを読み込みます．詳細は前回までのプログラムを確認してください．\n",
        "\n",
        "今回は2次元の画像データとしてMNISTデータセットを扱うため，\n",
        "データを`(チャンネル, 縦，横)`の形に並べ替えます．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlChw880IqDC"
      },
      "source": [
        "# load images\n",
        "with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n",
        "    x_train = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "x_train = x_train.reshape(-1, 784)\n",
        "\n",
        "with gzip.open('t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
        "    x_test = np.frombuffer(f.read(), np.uint8, offset=16)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "with gzip.open('train-labels-idx1-ubyte.gz', 'rb') as f:\n",
        "    y_train = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "with gzip.open('t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
        "    y_test = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "\n",
        "x_train = x_train.reshape(-1, 1, 28, 28)\n",
        "x_test = x_test.reshape(-1, 1, 28, 28)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgDd3iX2zmSV"
      },
      "source": [
        "## PyTorchを用いたネットワークモデルの定義\n",
        "畳み込みニューラルネットワークを定義します．\n",
        "\n",
        "ここでは，畳み込み層１層，全結合層２層から構成されるネットワークとします．\n",
        "\n",
        "１層目の畳み込み層は入力チャンネル数が１，出力する特徴マップ数が16，畳み込むフィルタサイズが3x3です．\n",
        "１つ目の全結合層は入力ユニット数は`(W/2)*(H/2)*num_kernel`とし，出力は128としています．\n",
        "出力層は入力が128，出力が10です．これらの各層の構成を`__init__`関数で定義します．\n",
        "\n",
        "次に，`forward`関数では，定義した層を接続して処理するように記述します．`forward`関数の引数xは入力データです．それを`__init__`関数で定義したconv1に与え，その出力を活性化関数であるrelu関数に与えます．そして，その出力をMaxPoolingである`pool`に与えて，プーリング処理結果を`h`として出力します．そして，出力`h`を`l1`に与えて全結合層の処理を行います．最終的に`l2`の全結合層の処理を行った出力`h`を戻り値としています．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNHnp_YczmY3"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, n_channels=1, filter_size=3, num_kernel=16, hidden_size=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(n_channels, num_kernel, kernel_size=filter_size, stride=1, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.l1 = nn.Linear(int(28/2) * int(28/2) * num_kernel, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, 10)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h = self.relu(self.conv(x))\n",
        "        h = self.pool(h)\n",
        "        h = h.view(h.size()[0], -1)\n",
        "        h = self.relu(self.l1(h))\n",
        "        h = self.l2(h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dwuvfouzmd7"
      },
      "source": [
        "## PyTorchを用いたネットワークの作成\n",
        "上のプログラムで定義したネットワークを作成します．\n",
        "\n",
        "CNNクラスを呼び出して，ネットワークモデルを定義します． また，GPUを使う場合（`use_cuda == True`）には，ネットワークモデルをGPUメモリ上に配置します．\n",
        "これにより，GPUを用いた演算が可能となります．\n",
        "\n",
        "学習を行う際の最適化方法としてモーメンタムSGD(モーメンタム付き確率的勾配降下法）を利用します． また，学習率を0.01，モーメンタムを0.9として引数に与えます．\n",
        "\n",
        "最後に，定義したネットワークの詳細情報を`torchsummary.summary()`関数を用いて表示します．\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23m79Eq-zmjl"
      },
      "source": [
        "model = CNN()\n",
        "if use_cuda:\n",
        "    model.cuda()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの情報を表示\n",
        "torchsummary.summary(model, (1, 28, 28))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUNa9Xe79vAG"
      },
      "source": [
        "## 学習\n",
        "読み込んだMNISTデータセットと作成したネットワークを用いて，学習を行います．\n",
        "\n",
        "1回の誤差を算出するデータ数（ミニバッチサイズ）を100，学習エポック数を10とします．\n",
        "\n",
        "次に，誤差関数を設定します．\n",
        "今回は，分類問題をあつかうため，クロスエントロピー誤差を計算するための`CrossEntropyLoss`を`criterion`として定義します．\n",
        "\n",
        "`model.train()`にて，Batch NormalizationやDropoutなどの学習と推論時に演算が異なる層の計算方法を学習用のものへと変更します．\n",
        "\n",
        "学習を開始します．\n",
        "\n",
        "前回までと同様に，ミニバッチサンプルを`x_batch`, `y_batch`としてランダムに抽出します．\n",
        "その後，これらを`torch.from_numpy`関数で，numpy arrayオブジェクトからPyTorchのTensorオブジェクトへ変換します．\n",
        "このとき．`type()`メソッドを適用することで，各Tensorオブジェクトのデータタイプを変更します．\n",
        "その後，GPUを用いて計算する場合には，`cuda()`メソッドでデータをGPU上へ保存します．\n",
        "\n",
        "\n",
        "上記の変換が完了したデータを`model(x_batch)`へ入力し，演算結果`y`を出力します．\n",
        "各クラスの確率yと教師ラベルtとの誤差を`criterion`で算出します．\n",
        "`model.zero_grad()`にて，ネットワークに蓄積していた勾配の情報をリセット（初期化）し，`loss.backward()`にて，今回の計算結果を元に誤差逆伝搬を行い，勾配情報を計算し，ネットワークへ蓄積します．\n",
        "最後に`optimizer.step()`で蓄積した誤差を元にネットワークのパラメータを更新します．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68RE3RTa76-W"
      },
      "source": [
        "# ミニバッチサイズ・エポック数の設定\n",
        "batch_size = 100\n",
        "epoch_num = 10\n",
        "num_train_data = x_train.shape[0]\n",
        "n_iter = num_train_data / batch_size\n",
        "\n",
        "# 誤差関数の設定\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "if use_cuda:\n",
        "    criterion.cuda()\n",
        "\n",
        "# ネットワークを学習モードへ変更\n",
        "model.train()\n",
        "\n",
        "iteration = 1\n",
        "start = time()\n",
        "for epoch in range(1, epoch_num+1):\n",
        "    sum_loss = 0.0\n",
        "    count = 0\n",
        "    \n",
        "    perm = np.random.permutation(num_train_data)\n",
        "    for i in range(0, num_train_data, batch_size):\n",
        "        x_batch = x_train[perm[i:i+batch_size]]\n",
        "        y_batch = y_train[perm[i:i+batch_size]]\n",
        "\n",
        "        x_batch = torch.from_numpy(x_batch).type(torch.float32)\n",
        "        y_batch = torch.from_numpy(y_batch).type(torch.int64)\n",
        "\n",
        "        if use_cuda:\n",
        "            x_batch = x_batch.cuda()\n",
        "            y_batch = y_batch.cuda()\n",
        "\n",
        "        y = model(x_batch)\n",
        "\n",
        "        loss = criterion(y, y_batch)\n",
        "        \n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item()\n",
        "        \n",
        "        pred = torch.argmax(y, dim=1)\n",
        "        count += torch.sum(pred == y_batch)\n",
        "        \n",
        "    print(\"epoch: {}, mean loss: {}, mean accuracy: {}, elapsed_time :{}\".format(epoch,\n",
        "                                                                                 sum_loss / n_iter,\n",
        "                                                                                 count.item() / num_train_data,\n",
        "                                                                                 time() - start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119eIrSmzmw6"
      },
      "source": [
        "## テスト\n",
        "学習したネットワークモデルを用いて評価を行います．\n",
        "\n",
        "まず，`model.eval()`を実行し，ネットワークの計算モードを評価モードへ変更します．\n",
        "\n",
        "その後，テストデータでの評価を行います．\n",
        "この時．`with torch.no_grad():`にて括っている範囲では，ネットワークの推論時に勾配計算のための情報を保持せずに順伝搬計算を行います．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoYVMRGLzm1I"
      },
      "source": [
        "# ネットワークを評価モードへ変更\n",
        "model.eval()\n",
        "\n",
        "# 評価の実行\n",
        "count = 0\n",
        "num_test_data = x_test.shape[0]\n",
        "\n",
        "# 勾配計算なしで順伝播計算を行うためのフラグ\n",
        "with torch.no_grad():\n",
        "    for i in range(num_test_data):\n",
        "        x = np.array([x_test[i]], dtype=np.float32)\n",
        "        t = y_test[i]\n",
        "\n",
        "        x = torch.from_numpy(x).type(torch.float32)\n",
        "\n",
        "        if use_cuda:\n",
        "            x = x.cuda()\n",
        "\n",
        "        y = model.forward(x)\n",
        "        pred = torch.argmax(y)\n",
        "        \n",
        "        if pred == t:\n",
        "            count += 1\n",
        "\n",
        "print(\"test accuracy: {}\".format(count / num_test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gzl4N5rC4j5u"
      },
      "source": [
        "## 課題\n",
        "1. ネットワーク構造を変えて実験しましょう． \n",
        "     * まず，1層目の畳み込み層のフィルタ数を32にしましょう．また，2層目の畳み込み層のフィルタ数を64にしましょう．\n",
        "    * 次に，中間層のユニット数を2048にしましょう．\n",
        "   \n",
        "\n",
        "\n",
        "2. 最適化の方法をAdamに変えて実験しましょう．\n",
        "\n",
        "\n",
        "\n",
        "3. エポック数やミニバッチサイズを変えて実験しましょう．\n",
        "    * まず，ミニバッチサイズを128にしましょう．\n",
        "    * 次に，エポック数を50にしましょう．"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjS-WptIg9Pf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
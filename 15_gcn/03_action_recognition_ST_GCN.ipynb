{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_action_recognition_ST-GCN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPSKO9jG/3+TbdEzl6WIg9N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/03_action_recognition_ST_GCN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4yIWKExMcV"
      },
      "source": [
        "#ST-GCNによる動作認識\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsAg0haiIC1a"
      },
      "source": [
        "#骨格データからの動作認識\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GslML25UII5Y"
      },
      "source": [
        "骨格データからの動作認識を行います.  \n",
        "動作認識は, その人が何の動作(投げる, 蹴る, ジャンプ...)をしているかを認識するタスクです.  \n",
        "動作認識には,画像などから行う手法もありますが,ここでは骨格データを使います."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42iCYGbOIktX"
      },
      "source": [
        "###骨格データ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B7C36eHRrWb"
      },
      "source": [
        "骨格データとは，フレームごとの関節座標です.  \n",
        "しかしながら,素のデータはただの座標であり, グラフとは言えません.  \n",
        "\n",
        "人間の構造は関節と関節の繋がりで表現できます.つまり人間はグラフとして表現できます.\n",
        "\n",
        "ノードの特徴（座標）とエッジ（関節の繋がり）を使うことで，骨格データをグラフとして表現します.  \n",
        "グラフで表現することで,関節間の関係性を考慮することができます.\n",
        "\n",
        "グラフで表現した骨格データをGraph Convolutional Networks(GCN)に通して, 何の動作をしているかを認識します.\n",
        "\n",
        "下の動画が，グラフ表現をした骨格データの例です.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vz6pKa3pt2kE"
      },
      "source": [
        "<!--\n",
        "<img src='https://drive.google.com/uc?id=1WrYd80u9buVcmBnpsgSZnzFlsYMih7Nr' width=30%>\n",
        "-->\n",
        "<!--\n",
        "<img src='https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/fig/03_throw_skeleton.gif?raw=true' width=30%>\n",
        "-->\n",
        "<img src='https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/fig/03_throw_skeleton.gif?raw=true' width=30%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty9FHb4yVB94"
      },
      "source": [
        "#Spatial Temporal Graph Convolutional Networks\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnhYROVaVSXp"
      },
      "source": [
        "GCNを使った骨格データからの動作認識の代表的な手法として, Spatial Temporal Graph Convolutional Networks(ST-GCN)[[arXiv](https://arxiv.org/abs/1801.07455)]があります."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwpdRsahuO-S"
      },
      "source": [
        "<!--\n",
        "<img src='https://drive.google.com/uc?id=1ZRf-NF4S0P1VwMxN2DrTFPeO4EJ5if3S' width=100%>\n",
        "-->\n",
        "<!--\n",
        "<img src='https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/fig/03_st-gcn.png?raw=true' width=100%>\n",
        "-->\n",
        "<img src='https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/fig/03_st-gcn.png?raw=true' width=100%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U_7UNeBWMN8"
      },
      "source": [
        "ST-GCNの特徴は,骨格データを2つのグラフ構造として表現したことです.\n",
        "- 空間グラフ：同一フレーム内の関節を結ぶグラフ　\n",
        "- 時間グラフ：隣接フレームの同一関節を結ぶグラフ\n",
        "\n",
        "空間グラフと時間グラフをGraph Covnolutionによって特徴を抽出することで，関節間の関係と, 時間的な変化を考慮しています. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAhpuPkHuf2E"
      },
      "source": [
        "<!--\n",
        "<img src='https://drive.google.com/uc?id=1FDOGPZxaIYs-be-6tZzPeBsrtMcBXcuv' width=30%>\n",
        "-->\n",
        "<!--\n",
        "<img src='https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/fig/03_st_graph.png?raw=true' width=30%>\n",
        "-->\n",
        "<img src='https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/fig/03_st_graph.png?raw=true' width=30%>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9_Um9Dy3ZeI"
      },
      "source": [
        "# 実装前の準備\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa7D5v0f3e_E"
      },
      "source": [
        "必要なモジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShT0XzlC4Glz"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78xIwKEz4G69"
      },
      "source": [
        "### GPU確認\n",
        "今回からGPUを使用して学習します. 確認してください."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVXaaWD54IBn",
        "outputId": "4aca60a4-6ada-4124-a900-29ace520ebb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Use CUDA:', torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Use CUDA: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Zpy-Z0YFJS"
      },
      "source": [
        "# データセット\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLl5gIVi4pTn"
      },
      "source": [
        "データセットをダンロードします.今回は，小さな独自のデータセットを用意したので，それを使用します.  \n",
        "動作クラス数は10クラス（0~9）です.動作は以下の通りです.\n",
        "*   0:　飲む\n",
        "*   1:　投げる\n",
        "*   2:　座る\n",
        "*   3:　立ち上がる\n",
        "*   4:　拍手\n",
        "*   5:　手を振る\n",
        "*   6:　蹴る\n",
        "*   7:　ジャンプ\n",
        "*   8:　敬礼\n",
        "*   9:　転倒\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb7J1jWy1Bpi"
      },
      "source": [
        "!wget -q --load-cookies /tmp/cookies.txt \"https://drive.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://drive.google.com/uc?export=download&id=1zzPvyMLY7jlyJ3phEZRePsNKhhzspD0u' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1zzPvyMLY7jlyJ3phEZRePsNKhhzspD0u\" -O data.zip && rm -rf /tmp/cookies.txt\n",
        "!unzip -q -o data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YktamQkB4wyB"
      },
      "source": [
        "メモ残し  \n",
        "自分のgithubからダウンロード  \n",
        "!wget -q https://github.com/sirakik/MPRGLecture/blob/master/15_gcn/data.zip?  raw=true -O data.zip  \n",
        "MPRGのgitubからダウンロード  \n",
        "!wget -q https://github.com/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/15_gcn/data.zip?raw=true -O data.zip  \n",
        "!unzip -q -o data.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYixFxzPfgqd"
      },
      "source": [
        "学習データ数が2000(10クラス×200データ)，　評価データ数が200(10クラス×20データ)あります.\n",
        "\n",
        "データの構造を確認します.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi7FLBnJ-156",
        "outputId": "b9676918-547c-4aec-bf16-3ec04047fba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_data = np.load(\"data/test_data.npy\")\n",
        "print(test_data[0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 80, 25)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftiwD1KhoFVS"
      },
      "source": [
        "(次元数，フレーム数，関節数)の構造です.  \n",
        "1データあたり,3次元座標の25関節が80フレーム分入っています."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGAvBo-MqpJy"
      },
      "source": [
        "# データを読み込むための関数\n",
        "class Feeder(torch.utils.data.Dataset):\n",
        "  def __init__(self, data_path, label_path):\n",
        "      super().__init__()\n",
        "      self.label = np.load(label_path)\n",
        "      self.data = np.load(data_path)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.label)\n",
        "\n",
        "  def __iter__(self):\n",
        "      return self\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      data = np.array(self.data[index])\n",
        "      label = self.label[index]\n",
        "\n",
        "      return data, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEA6NlHGaGSb"
      },
      "source": [
        "### 隣接行列を作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFYyypxdo3_G"
      },
      "source": [
        "今は座標データ（ノード特徴）しかないため，グラフではありません．  \n",
        "接続関係を定義して，グラフにします．接続関係の表現には隣接行列を使用します.  \n",
        "class化しておきます. モデルの定義する際に呼び出します.\n",
        "\n",
        "隣接行列を手作業で編集するのは大変であるため，接続関係を配列で用意し，それをもとに隣接行列を作ります."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFV6MAuFds7V"
      },
      "source": [
        "class Graph():\n",
        "  def __init__(self, hop_size):\n",
        "    # エッジ配列を宣言します. 集合としては{{始点, 終点}, {始点, 終点}, {始点, 終点}...}のように一つのエッジを要素として宣言します.\n",
        "    self.get_edge()\n",
        "    \n",
        "    # hop: hop数分離れた関節を結びます.\n",
        "    # 例えばhop=2だと, 手首は肘だけではなく肩にも繋がっています.\n",
        "    self.hop_size = hop_size \n",
        "    self.hop_dis = self.get_hop_distance(self.num_node, self.edge, hop_size=hop_size)\n",
        "\n",
        "    # 隣接行列を作ります.ここではhop数ごとに隣接行列を作成します.\n",
        "    # hopが2の時, 0hop, 1hop, 2hopの３つの隣接行列が作成されます.\n",
        "    # 複数の生成方法が論文中に提案されています. 今回はわかりやすいものを使いました.\n",
        "    self.get_adjacency() \n",
        "\n",
        "  def __str__(self):\n",
        "    return self.A\n",
        "\n",
        "  def get_edge(self):\n",
        "    self.num_node = 25\n",
        "    self_link = [(i, i) for i in range(self.num_node)] # ループ\n",
        "    neighbor_base = [(1, 2), (2, 21), (3, 21), (4, 3), (5, 21),\n",
        "                      (6, 5), (7, 6), (8, 7), (9, 21), (10, 9),\n",
        "                      (11, 10), (12, 11), (13, 1), (14, 13), (15, 14),\n",
        "                      (16, 15), (17, 1), (18, 17), (19, 18), (20, 19),\n",
        "                      (22, 23), (23, 8), (24, 25), (25, 12)]\n",
        "    neighbor_link = [(i - 1, j - 1) for (i, j) in neighbor_base]\n",
        "    self.edge = self_link + neighbor_link\n",
        "\n",
        "  def get_adjacency(self):\n",
        "    valid_hop = range(0, self.hop_size + 1, 1)\n",
        "    adjacency = np.zeros((self.num_node, self.num_node))\n",
        "    for hop in valid_hop:\n",
        "        adjacency[self.hop_dis == hop] = 1\n",
        "    normalize_adjacency = self.normalize_digraph(adjacency)\n",
        "    A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
        "    for i, hop in enumerate(valid_hop):\n",
        "        A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis == hop]\n",
        "    self.A = A\n",
        "\n",
        "  def get_hop_distance(self, num_node, edge, hop_size):\n",
        "    A = np.zeros((num_node, num_node))\n",
        "    for i, j in edge:\n",
        "        A[j, i] = 1\n",
        "        A[i, j] = 1\n",
        "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
        "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(hop_size + 1)]\n",
        "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
        "    for d in range(hop_size, -1, -1):\n",
        "        hop_dis[arrive_mat[d]] = d\n",
        "    return hop_dis\n",
        "\n",
        "  def normalize_digraph(self, A):\n",
        "    Dl = np.sum(A, 0)\n",
        "    num_node = A.shape[0]\n",
        "    Dn = np.zeros((num_node, num_node))\n",
        "    for i in range(num_node):\n",
        "        if Dl[i] > 0:\n",
        "            Dn[i, i] = Dl[i]**(-1)\n",
        "    DAD = np.dot(A, Dn)\n",
        "    return DAD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTCb52YUYHYh"
      },
      "source": [
        "#ST-GCN実装\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H6jSUH9YdCQ"
      },
      "source": [
        "###空間グラフの畳み込み  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvIeqwf7tT1K"
      },
      "source": [
        "まずは，空間グラフ(人間の接続パターン)のグラフ畳み込みを実装します.  \n",
        "式は前回(Graph Convolutional Networksによるノード分類)に示したGraph Convolutionとほぼ同じです.\n",
        "\\begin{equation}\n",
        "{\\bf H}_{out}=\\sum_{j}{\\bf\\tilde D}^{-\\frac{1}{2}}_j{\\bf\\tilde A}_j{\\bf\\tilde D}^{-\\frac{1}{2}}_j{\\bf H}_{in}{\\bf W}_{j}\n",
        "\\end{equation}\n",
        "hop数分の隣接行列($j$:隣接行列の数)があるため，各隣接行列で畳み込んでから，特徴を足し合わせています.  \n",
        "\n",
        "高速化や，今後の拡張性のため，前回のGCとは実装を変えています.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrffcNi0ZCP7"
      },
      "source": [
        "class SpatialGraphConvolution(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, s_kernel_size):\n",
        "    super().__init__()\n",
        "    self.s_kernel_size = s_kernel_size\n",
        "    self.conv = nn.Conv2d(in_channels=in_channels,\n",
        "                          out_channels=out_channels * s_kernel_size,\n",
        "                          kernel_size=1)\n",
        "    \n",
        "  def forward(self, x, A):\n",
        "    x = self.conv(x)\n",
        "    n, kc, t, v = x.size()\n",
        "    x = x.view(n, self.s_kernel_size, kc//self.s_kernel_size, t, v)\n",
        "    # 隣接行列にGCを行い, 特徴を足し合わせています.\n",
        "    x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
        "    return x.contiguous()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kosLltaeYg55"
      },
      "source": [
        "###時間グラフの畳み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5T1vQz6bvsu"
      },
      "source": [
        "時間グラフは,グラフ畳み込み処理ではなく一般的な2d畳み込み処理で実装できます.  \n",
        "特徴マップは（フレーム数×関節数)の形になっています. 同一関節をフレーム方向に繋いだものが時間グラフです.  \n",
        "フレーム方向に畳み込めばいいため（$T\\times 1$）の2d畳み込みフィルターで実装できます.\n",
        "\n",
        "また, ST-GCNは, 空間グラフと時間グラフの畳み込みを交互に行います.  \n",
        "これを繰り返すので, 空間グラフと時間グラフ，その他(活性化関数やdropout)を備えたクラス(STGC_block)を作っておきます."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPcF2Od9AvmA"
      },
      "source": [
        "class STGC_block(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride, t_kernel_size, A_size, dropout=0.5):\n",
        "    super().__init__()\n",
        "    # 空間グラフの畳み込み\n",
        "    self.sgc = SpatialGraphConvolution(in_channels=in_channels,\n",
        "                                       out_channels=out_channels,\n",
        "                                       s_kernel_size=A_size[0])\n",
        "    \n",
        "    # Learnable weight matrix M エッジに重みを与えます. どのエッジが重要かを学習します.\n",
        "    self.M = nn.Parameter(torch.ones(A_size))\n",
        "\n",
        "    self.tgc = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
        "                            nn.ReLU(),\n",
        "                            nn.Dropout(dropout),\n",
        "                            nn.Conv2d(out_channels,\n",
        "                                      out_channels,\n",
        "                                      (t_kernel_size, 1),\n",
        "                                      (stride, 1),\n",
        "                                      ((t_kernel_size - 1) // 2, 0)),\n",
        "                            nn.BatchNorm2d(out_channels),\n",
        "                            nn.ReLU())\n",
        "\n",
        "  def forward(self, x, A):\n",
        "    x = self.tgc(self.sgc(x, A * self.M))\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy0nx9SvYod1"
      },
      "source": [
        "###ネットワークモデル"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzAe1GgpZv7k"
      },
      "source": [
        "class ST_GCN(nn.Module):\n",
        "  def __init__(self, num_classes, in_channels, t_kernel_size, hop_size):\n",
        "    super().__init__()\n",
        "    # グラフ作成\n",
        "    graph = Graph(hop_size)\n",
        "    A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
        "    self.register_buffer('A', A)\n",
        "    A_size = A.size()\n",
        "  \n",
        "    # Batch Normalization\n",
        "    self.bn = nn.BatchNorm1d(in_channels * A_size[1])\n",
        "    \n",
        "    # STGC_blocks\n",
        "    self.stgc1 = STGC_block(in_channels, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc2 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc3 = STGC_block(32, 32, 1, t_kernel_size, A_size)\n",
        "    self.stgc4 = STGC_block(32, 64, 2, t_kernel_size, A_size)\n",
        "    self.stgc5 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
        "    self.stgc6 = STGC_block(64, 64, 1, t_kernel_size, A_size)\n",
        "\n",
        "    # Prediction\n",
        "    self.fc = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Batch Normalization\n",
        "    N, C, T, V = x.size() # batch, channel, frame, node\n",
        "    x = x.permute(0, 3, 1, 2).contiguous().view(N, V * C, T)\n",
        "    x = self.bn(x)\n",
        "    x = x.view(N, V, C, T).permute(0, 2, 3, 1).contiguous()\n",
        "\n",
        "    # STGC_blocks\n",
        "    x = self.stgc1(x, self.A)\n",
        "    x = self.stgc2(x, self.A)\n",
        "    x = self.stgc3(x, self.A)\n",
        "    x = self.stgc4(x, self.A)\n",
        "    x = self.stgc5(x, self.A)\n",
        "    x = self.stgc6(x, self.A)\n",
        "\n",
        "    # Prediction\n",
        "    x = F.avg_pool2d(x, x.size()[2:])\n",
        "    x = x.view(N, -1, 1, 1)\n",
        "    x = self.fc(x)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDCn2cuIYPG1"
      },
      "source": [
        "#学習\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk-AMCVb5jqM",
        "outputId": "b49a969b-1f55-4d94-c7c9-595c983b3e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "NUM_EPOCH = 100\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# モデルを作成\n",
        "model = ST_GCN(num_classes=10, \n",
        "                  in_channels=3,\n",
        "                  t_kernel_size=9, # 時間グラフ畳み込みのカーネルサイズ (t_kernel_size × 1)\n",
        "                  hop_size=2).cuda()\n",
        "\n",
        "# オプティマイザ\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 誤差関数\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# データセットの用意\n",
        "data_loader = dict()\n",
        "data_loader['train'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='data/train_data.npy', label_path='data/train_label.npy'), batch_size=BATCH_SIZE, shuffle=True,)\n",
        "data_loader['test'] = torch.utils.data.DataLoader(dataset=Feeder(data_path='data/test_data.npy', label_path='data/test_label.npy'), batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# モデルを学習モードに変更\n",
        "model.train()\n",
        "\n",
        "# 学習開始\n",
        "for epoch in range(1, NUM_EPOCH+1):\n",
        "  correct = 0\n",
        "  sum_loss = 0\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['train']):\n",
        "    data = data.cuda()\n",
        "    label = label.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    sum_loss += loss.item()\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct += (predict == label).sum().item()\n",
        "\n",
        "  print('# Epoch: {} | Loss: {:.4f} | Accuracy: {:.4f}'.format(epoch, sum_loss/len(data_loader['train'].dataset), (100. * correct / len(data_loader['train'].dataset))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Epoch: 1 | Loss: 0.0362 | Accuracy: 15.2500\n",
            "# Epoch: 2 | Loss: 0.0348 | Accuracy: 21.0500\n",
            "# Epoch: 3 | Loss: 0.0335 | Accuracy: 24.2500\n",
            "# Epoch: 4 | Loss: 0.0326 | Accuracy: 25.3000\n",
            "# Epoch: 5 | Loss: 0.0316 | Accuracy: 28.1500\n",
            "# Epoch: 6 | Loss: 0.0299 | Accuracy: 31.8500\n",
            "# Epoch: 7 | Loss: 0.0286 | Accuracy: 36.2000\n",
            "# Epoch: 8 | Loss: 0.0267 | Accuracy: 41.9500\n",
            "# Epoch: 9 | Loss: 0.0236 | Accuracy: 47.1500\n",
            "# Epoch: 10 | Loss: 0.0211 | Accuracy: 54.5000\n",
            "# Epoch: 11 | Loss: 0.0189 | Accuracy: 58.5500\n",
            "# Epoch: 12 | Loss: 0.0179 | Accuracy: 59.2500\n",
            "# Epoch: 13 | Loss: 0.0171 | Accuracy: 61.4000\n",
            "# Epoch: 14 | Loss: 0.0167 | Accuracy: 62.9000\n",
            "# Epoch: 15 | Loss: 0.0165 | Accuracy: 63.1500\n",
            "# Epoch: 16 | Loss: 0.0162 | Accuracy: 63.3000\n",
            "# Epoch: 17 | Loss: 0.0155 | Accuracy: 65.5000\n",
            "# Epoch: 18 | Loss: 0.0151 | Accuracy: 66.8000\n",
            "# Epoch: 19 | Loss: 0.0139 | Accuracy: 71.6000\n",
            "# Epoch: 20 | Loss: 0.0132 | Accuracy: 71.0500\n",
            "# Epoch: 21 | Loss: 0.0127 | Accuracy: 72.5500\n",
            "# Epoch: 22 | Loss: 0.0118 | Accuracy: 76.0000\n",
            "# Epoch: 23 | Loss: 0.0111 | Accuracy: 76.5000\n",
            "# Epoch: 24 | Loss: 0.0114 | Accuracy: 75.1000\n",
            "# Epoch: 25 | Loss: 0.0105 | Accuracy: 77.2500\n",
            "# Epoch: 26 | Loss: 0.0099 | Accuracy: 79.0000\n",
            "# Epoch: 27 | Loss: 0.0100 | Accuracy: 77.9000\n",
            "# Epoch: 28 | Loss: 0.0101 | Accuracy: 79.1000\n",
            "# Epoch: 29 | Loss: 0.0093 | Accuracy: 79.3500\n",
            "# Epoch: 30 | Loss: 0.0095 | Accuracy: 79.3000\n",
            "# Epoch: 31 | Loss: 0.0084 | Accuracy: 82.1500\n",
            "# Epoch: 32 | Loss: 0.0081 | Accuracy: 83.0000\n",
            "# Epoch: 33 | Loss: 0.0081 | Accuracy: 82.2000\n",
            "# Epoch: 34 | Loss: 0.0083 | Accuracy: 81.8000\n",
            "# Epoch: 35 | Loss: 0.0078 | Accuracy: 83.4000\n",
            "# Epoch: 36 | Loss: 0.0081 | Accuracy: 82.7500\n",
            "# Epoch: 37 | Loss: 0.0076 | Accuracy: 83.7500\n",
            "# Epoch: 38 | Loss: 0.0079 | Accuracy: 82.8500\n",
            "# Epoch: 39 | Loss: 0.0081 | Accuracy: 81.4500\n",
            "# Epoch: 40 | Loss: 0.0079 | Accuracy: 83.0500\n",
            "# Epoch: 41 | Loss: 0.0074 | Accuracy: 84.3000\n",
            "# Epoch: 42 | Loss: 0.0068 | Accuracy: 84.9000\n",
            "# Epoch: 43 | Loss: 0.0064 | Accuracy: 86.5000\n",
            "# Epoch: 44 | Loss: 0.0068 | Accuracy: 84.8000\n",
            "# Epoch: 45 | Loss: 0.0071 | Accuracy: 84.7000\n",
            "# Epoch: 46 | Loss: 0.0064 | Accuracy: 86.1500\n",
            "# Epoch: 47 | Loss: 0.0064 | Accuracy: 86.5000\n",
            "# Epoch: 48 | Loss: 0.0068 | Accuracy: 84.8500\n",
            "# Epoch: 49 | Loss: 0.0062 | Accuracy: 86.7000\n",
            "# Epoch: 50 | Loss: 0.0062 | Accuracy: 86.5500\n",
            "# Epoch: 51 | Loss: 0.0061 | Accuracy: 87.1500\n",
            "# Epoch: 52 | Loss: 0.0059 | Accuracy: 86.6000\n",
            "# Epoch: 53 | Loss: 0.0058 | Accuracy: 86.7000\n",
            "# Epoch: 54 | Loss: 0.0057 | Accuracy: 87.5500\n",
            "# Epoch: 55 | Loss: 0.0058 | Accuracy: 86.9500\n",
            "# Epoch: 56 | Loss: 0.0060 | Accuracy: 86.5000\n",
            "# Epoch: 57 | Loss: 0.0059 | Accuracy: 87.2500\n",
            "# Epoch: 58 | Loss: 0.0063 | Accuracy: 85.3500\n",
            "# Epoch: 59 | Loss: 0.0058 | Accuracy: 86.8500\n",
            "# Epoch: 60 | Loss: 0.0054 | Accuracy: 87.5500\n",
            "# Epoch: 61 | Loss: 0.0057 | Accuracy: 87.4000\n",
            "# Epoch: 62 | Loss: 0.0054 | Accuracy: 88.4000\n",
            "# Epoch: 63 | Loss: 0.0053 | Accuracy: 89.2500\n",
            "# Epoch: 64 | Loss: 0.0057 | Accuracy: 87.5000\n",
            "# Epoch: 65 | Loss: 0.0051 | Accuracy: 87.8500\n",
            "# Epoch: 66 | Loss: 0.0050 | Accuracy: 89.1000\n",
            "# Epoch: 67 | Loss: 0.0050 | Accuracy: 88.7000\n",
            "# Epoch: 68 | Loss: 0.0050 | Accuracy: 89.3500\n",
            "# Epoch: 69 | Loss: 0.0053 | Accuracy: 89.3000\n",
            "# Epoch: 70 | Loss: 0.0053 | Accuracy: 88.6000\n",
            "# Epoch: 71 | Loss: 0.0047 | Accuracy: 89.2500\n",
            "# Epoch: 72 | Loss: 0.0047 | Accuracy: 89.7500\n",
            "# Epoch: 73 | Loss: 0.0048 | Accuracy: 88.9000\n",
            "# Epoch: 74 | Loss: 0.0051 | Accuracy: 88.6000\n",
            "# Epoch: 75 | Loss: 0.0049 | Accuracy: 89.1000\n",
            "# Epoch: 76 | Loss: 0.0051 | Accuracy: 88.7500\n",
            "# Epoch: 77 | Loss: 0.0048 | Accuracy: 89.0000\n",
            "# Epoch: 78 | Loss: 0.0048 | Accuracy: 89.2500\n",
            "# Epoch: 79 | Loss: 0.0049 | Accuracy: 88.2500\n",
            "# Epoch: 80 | Loss: 0.0048 | Accuracy: 88.2000\n",
            "# Epoch: 81 | Loss: 0.0045 | Accuracy: 89.3500\n",
            "# Epoch: 82 | Loss: 0.0047 | Accuracy: 89.4500\n",
            "# Epoch: 83 | Loss: 0.0046 | Accuracy: 89.3500\n",
            "# Epoch: 84 | Loss: 0.0044 | Accuracy: 89.8500\n",
            "# Epoch: 85 | Loss: 0.0045 | Accuracy: 89.9500\n",
            "# Epoch: 86 | Loss: 0.0042 | Accuracy: 90.2000\n",
            "# Epoch: 87 | Loss: 0.0043 | Accuracy: 90.5500\n",
            "# Epoch: 88 | Loss: 0.0044 | Accuracy: 89.9500\n",
            "# Epoch: 89 | Loss: 0.0045 | Accuracy: 90.2500\n",
            "# Epoch: 90 | Loss: 0.0047 | Accuracy: 89.7000\n",
            "# Epoch: 91 | Loss: 0.0042 | Accuracy: 90.4000\n",
            "# Epoch: 92 | Loss: 0.0042 | Accuracy: 89.6500\n",
            "# Epoch: 93 | Loss: 0.0049 | Accuracy: 88.8000\n",
            "# Epoch: 94 | Loss: 0.0044 | Accuracy: 89.2500\n",
            "# Epoch: 95 | Loss: 0.0043 | Accuracy: 90.3500\n",
            "# Epoch: 96 | Loss: 0.0042 | Accuracy: 90.5000\n",
            "# Epoch: 97 | Loss: 0.0038 | Accuracy: 91.1000\n",
            "# Epoch: 98 | Loss: 0.0047 | Accuracy: 90.3000\n",
            "# Epoch: 99 | Loss: 0.0044 | Accuracy: 90.7000\n",
            "# Epoch: 100 | Loss: 0.0039 | Accuracy: 91.8000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJmolf-w7yDJ"
      },
      "source": [
        "#評価\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHM5wt_670Li",
        "outputId": "7711c9c9-c722-4b3d-9be2-a43bd90a81e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "# モデルを評価モードに変更\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "confusion_matrix = np.zeros((10, 10))\n",
        "with torch.no_grad():\n",
        "  for batch_idx, (data, label) in enumerate(data_loader['test']):\n",
        "    data = data.cuda()\n",
        "    label = label.cuda()\n",
        "\n",
        "    output = model(data)\n",
        "\n",
        "    _, predict = torch.max(output.data, 1)\n",
        "    correct += (predict == label).sum().item()\n",
        "\n",
        "    for l, p in zip(label.view(-1), predict.view(-1)):\n",
        "      confusion_matrix[l.long(), p.long()] += 1\n",
        "\n",
        "len_cm = len(confusion_matrix)\n",
        "for i in range(len_cm):\n",
        "    sum_cm = np.sum(confusion_matrix[i])\n",
        "    for j in range(len_cm):\n",
        "        confusion_matrix[i][j] = 100 * (confusion_matrix[i][j] / sum_cm)\n",
        "\n",
        "classes = ['drink', 'throw', 'sit down', 'stand up', 'clapping', 'hand waving', 'kicking', 'jump up', 'salute', 'falling down']\n",
        "plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion matrix')\n",
        "plt.tight_layout()\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation=45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "plt.ylabel('True')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('# Test Accuracy: {:.3f}[%]'.format(100. * correct / len(data_loader['test'].dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "# Test Accuracy: 82.000[%]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep mutual learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep mutual learning (DML)とは，複数のネットワークを使った相互学習手法です．Knowledge distillationでは，Teacherネットワークという事前学習済みの大きなネットワークの出力を，小さなStudentネットワークに真似させることで，Studentネットワークの性能を向上させていました．DMLでは，未学習のStudentネットワークだけを使って，2つのネットワークの出力をお互いに真似し合いながら学習します．以下に，クラス分類問題を解くネットワークにおけるDMLの概要を示します．DMLの学習は，基本的にknowledge distillationと似ていますが，2つのStudentネットワークを同時に学習するところが異なります．その際，2つのネットワークの出力のKL divergenceを損失関数として用います．2つのStudentのサイズは，同じでも異なっていてもうまく機能します．\n",
    "\n",
    "<img src=\"https://paper-attachments.dropbox.com/s_87B2D47FBD0A698415C3853F712E17ACC67F633356B04D1BA9138A68175CE0AD_1596763062871_image.png\" width = 40%>\n",
    "\n",
    "## 学習方法\n",
    "\n",
    "DMLは，各イテレーションで2つのネットワークを同時に学習させます．\n",
    "2つのStudentネットワークを$\\theta_1, \\theta_2$とすると，以下の手順を繰り返します．\n",
    "\n",
    "1. Student $\\theta_1, \\theta_2$に画像を入力\n",
    "2. Student $\\theta_1$の損失を計算 ＆ backprop\n",
    "3. Student $\\theta_1$を更新\n",
    "4. 更新後のStudent $\\theta_1$に再び画像を入力\n",
    "5. Student $\\theta_2$の損失を計算 ＆ backprop\n",
    "6. Student $\\theta_2$を更新\n",
    "\n",
    "\n",
    "### 損失関数\n",
    "\n",
    "Student 1と2の損失関数は同じであるため，Student 1の損失関数のみを説明します．DMLでは，蒸留と同じく2種類の損失関数の和を最終的な損失関数としています．\n",
    "\n",
    "1つ目は，教師ラベル(hard target)との損失を計算するためのcross entropy lossです．これは，通常の教師あり学習で使用するものと同じです．具体的な式は以下のように表されます．\n",
    "\n",
    "$$L^{\\theta_1}_{hard} = - \\sum^C_i{t_i \\log{p^{\\theta_1}_i(x)}}$$\n",
    "\n",
    "ここで，$C$はクラス数，$t_i \\in \\{0,1\\}$は$i$番目クラスの教師ラベル値，$x$は入力画像，$p^{\\theta_1}_i$はStudent $\\theta_1$の出力をsoftmax関数で正規化した後の，$i$番目クラスの確率値です．\n",
    "\n",
    "2つ目は，相互学習用の損失を計算するためのKullback-Leibler divergence lossです．具体的な式は以下のように表されます．\n",
    "\n",
    "$$L^{\\theta_1}_{soft} = D_{KL}(p^{\\theta_2} || p^{\\theta_1}) = \\sum^C_i{p^{\\theta_2}_i(x) \\log{\\frac{p^{\\theta_1}_i(x)}{p^{\\theta_2}_i(x)}}}$$\n",
    "\n",
    "Kullback-Leibler divergence (KL divergence)とは，2つの確率分布間の相違度を表す指標です．下の図のように，確率分布 $p,q$ が似ている場合（左図）にはKL divergence $D_{KL}(p||q)$ は小さくなり，似ていない場合（右図）には大きくなります．このKL divergenceの値が小さくなるように（つまり，2つのネットワークの出力が似るように）ネットワークを学習します．\n",
    "\n",
    "<img src=\"https://paper-attachments.dropbox.com/s_87B2D47FBD0A698415C3853F712E17ACC67F633356B04D1BA9138A68175CE0AD_1601892394474_image.png\" width = 60%>\n",
    "\n",
    "最終的なLossは以下のように，2つの損失関数の和です．\n",
    "$$L^{\\theta_1} = L^{\\theta_1}_{label} + L^{\\theta_1}_{mutual}$$\n",
    "\n",
    "\n",
    "### ３つ以上のネットワークを使った学習への拡張\n",
    "\n",
    "DMLは3つ以上のネットワークで学習させることも可能です．学習方法は，先ほど説明した2つのネットワークを学習させる場合と同様ですが，相互学習用の損失関数の計算が以下のように少し複雑になります．\n",
    "\n",
    "$$L^{\\theta_k}_{soft} = \\frac{1}{K-1} \\sum^K_{l=1, l \\neq k} D_{KL}(p^{\\theta_l} || p^{\\theta_k})$$\n",
    "\n",
    "ここで$K$はネットワーク数です．この式は，自分以外のネットワークとのKL diverdenceを求め，その平均値をLossとすることを表しています．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワークのdeep mutual learning\n",
    "クラス分類問題を解くネットワークに対して，deep mutual learningを適用した学習を行います．\n",
    "データセットには一般物体認識用のデータセットであるCIFAR-10を使います．CIFAR-10は10クラスの画像からなるデータセットです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポック数の設定\n",
    "NUM_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# データローダーの準備\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset/CIFAR-10\", train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset/CIFAR-10\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, num_workers=10)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=1000, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの用意\n",
    "畳み込みネットワークを定義します．ここでは，2層の畳み込み層と3層の全結合層により構成されるネットワークとします．\n",
    "widen_factorという引数は，畳み込み層のフィルタ数と全結合層のユニット数をデフォルトの値から何倍するかを決定するものです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, widen_factor=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16*widen_factor, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16*widen_factor, 32*widen_factor, kernel_size=3, stride=1, padding=1)\n",
    "        self.l1 = nn.Linear(8*8*32*widen_factor, 1024*widen_factor)\n",
    "        self.l2 = nn.Linear(1024*widen_factor, 1024*widen_factor)\n",
    "        self.l3 = nn.Linear(1024*widen_factor, 10)\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.pool(self.act(self.conv1(x)))\n",
    "        h = self.pool(self.act(self.conv2(h)))\n",
    "        h = h.view(h.size()[0], -1)\n",
    "        h = self.act(self.l1(h))\n",
    "        h = self.act(self.l2(h))\n",
    "        h = self.l3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studentネットワーク単体の学習（DMLなしの場合）\n",
    "後で比較をするために，Studentネットワークに対して，deep mutual learningを適用しない通常の学習を行います．\n",
    "Studentネットワークを1つだけ用意して，正解ラベルとのクロスエントロピー損失のみで学習します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studentネットワークの用意\n",
    "Studentネットワークを作成します．Teacherネットワークよりも小さなネットワークにするため widen_factor=1 にします．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "              ReLU-2           [-1, 16, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 16, 16, 16]               0\n",
      "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
      "              ReLU-5           [-1, 32, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 32, 8, 8]               0\n",
      "            Linear-7                 [-1, 1024]       2,098,176\n",
      "              ReLU-8                 [-1, 1024]               0\n",
      "            Linear-9                 [-1, 1024]       1,049,600\n",
      "             ReLU-10                 [-1, 1024]               0\n",
      "           Linear-11                   [-1, 10]          10,250\n",
      "================================================================\n",
      "Total params: 3,163,114\n",
      "Trainable params: 3,163,114\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.45\n",
      "Params size (MB): 12.07\n",
      "Estimated Total Size (MB): 12.53\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#ネットワークモデルを指定\n",
    "student = CNN(widen_factor=1).cuda()\n",
    "# student のサマリーを表示\n",
    "torchsummary.summary(model=student, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習 & 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mean loss: 1.7062900456626091, mean accuracy: 0.36942, elapsed_time :4.424213409423828\n",
      "epoch: 2, mean loss: 1.3191453308400596, mean accuracy: 0.52278, elapsed_time :9.082408666610718\n",
      "epoch: 3, mean loss: 1.159928763080436, mean accuracy: 0.58454, elapsed_time :13.48412823677063\n",
      "epoch: 4, mean loss: 1.0561279934233108, mean accuracy: 0.6236, elapsed_time :18.020206212997437\n",
      "epoch: 5, mean loss: 0.9795953059745262, mean accuracy: 0.65478, elapsed_time :22.593263626098633\n",
      "epoch: 6, mean loss: 0.9179628053513329, mean accuracy: 0.67376, elapsed_time :27.0924870967865\n",
      "epoch: 7, mean loss: 0.8649502888969753, mean accuracy: 0.69548, elapsed_time :31.726054906845093\n",
      "epoch: 8, mean loss: 0.81743352088477, mean accuracy: 0.71226, elapsed_time :36.225003480911255\n",
      "epoch: 9, mean loss: 0.789827624054821, mean accuracy: 0.72382, elapsed_time :40.71925950050354\n",
      "epoch: 10, mean loss: 0.75882277971186, mean accuracy: 0.73308, elapsed_time :45.12921738624573\n",
      "epoch: 11, mean loss: 0.7257515014437459, mean accuracy: 0.7449, elapsed_time :49.540034770965576\n",
      "epoch: 12, mean loss: 0.7032746956552691, mean accuracy: 0.75324, elapsed_time :54.039451599121094\n",
      "epoch: 13, mean loss: 0.6742333356300583, mean accuracy: 0.7635, elapsed_time :58.44028878211975\n",
      "epoch: 14, mean loss: 0.6559151667158317, mean accuracy: 0.7696, elapsed_time :62.96032953262329\n",
      "epoch: 15, mean loss: 0.6379776155895285, mean accuracy: 0.77528, elapsed_time :67.35190272331238\n",
      "epoch: 16, mean loss: 0.6223261624269778, mean accuracy: 0.78168, elapsed_time :72.25607776641846\n",
      "epoch: 17, mean loss: 0.6105552079046473, mean accuracy: 0.78514, elapsed_time :77.80960607528687\n",
      "epoch: 18, mean loss: 0.5869495813041696, mean accuracy: 0.79128, elapsed_time :83.34374117851257\n",
      "epoch: 19, mean loss: 0.5778372371593095, mean accuracy: 0.79532, elapsed_time :88.84378600120544\n",
      "epoch: 20, mean loss: 0.560650957438647, mean accuracy: 0.80174, elapsed_time :94.3934977054596\n",
      "epoch: 21, mean loss: 0.5486024423404727, mean accuracy: 0.8078, elapsed_time :99.90923261642456\n",
      "epoch: 22, mean loss: 0.5349954784945454, mean accuracy: 0.81192, elapsed_time :105.4051616191864\n",
      "epoch: 23, mean loss: 0.5294928331585491, mean accuracy: 0.81318, elapsed_time :110.89800691604614\n",
      "epoch: 24, mean loss: 0.5098137164397922, mean accuracy: 0.82148, elapsed_time :116.40752410888672\n",
      "epoch: 25, mean loss: 0.5074408793502756, mean accuracy: 0.81894, elapsed_time :121.94136810302734\n",
      "epoch: 26, mean loss: 0.4900592983035785, mean accuracy: 0.82768, elapsed_time :127.46079921722412\n",
      "epoch: 27, mean loss: 0.4840009277662658, mean accuracy: 0.8305, elapsed_time :132.99067497253418\n",
      "epoch: 28, mean loss: 0.47499714170575447, mean accuracy: 0.83192, elapsed_time :138.5996377468109\n",
      "epoch: 29, mean loss: 0.4613596231431302, mean accuracy: 0.83866, elapsed_time :144.20220375061035\n",
      "epoch: 30, mean loss: 0.46115365342410936, mean accuracy: 0.8387, elapsed_time :149.79720664024353\n",
      "epoch: 31, mean loss: 0.44350958588864187, mean accuracy: 0.84394, elapsed_time :155.25745701789856\n",
      "epoch: 32, mean loss: 0.43998385855304006, mean accuracy: 0.84406, elapsed_time :160.71265602111816\n",
      "epoch: 33, mean loss: 0.43032672231459557, mean accuracy: 0.84842, elapsed_time :166.21108603477478\n",
      "epoch: 34, mean loss: 0.4195454514316281, mean accuracy: 0.85196, elapsed_time :171.77108597755432\n",
      "epoch: 35, mean loss: 0.4212592526355668, mean accuracy: 0.85222, elapsed_time :177.21309208869934\n",
      "epoch: 36, mean loss: 0.4153370114657885, mean accuracy: 0.85224, elapsed_time :182.71703910827637\n",
      "epoch: 37, mean loss: 0.4068150139983048, mean accuracy: 0.85738, elapsed_time :187.50433373451233\n",
      "epoch: 38, mean loss: 0.40135049661788186, mean accuracy: 0.85802, elapsed_time :192.0454704761505\n",
      "epoch: 39, mean loss: 0.39242721096519617, mean accuracy: 0.86168, elapsed_time :196.60637211799622\n",
      "epoch: 40, mean loss: 0.38392306727064235, mean accuracy: 0.86484, elapsed_time :201.21095824241638\n",
      "epoch: 41, mean loss: 0.37475694977985624, mean accuracy: 0.8676, elapsed_time :205.95796298980713\n",
      "epoch: 42, mean loss: 0.37021360119514146, mean accuracy: 0.86944, elapsed_time :210.68727612495422\n",
      "epoch: 43, mean loss: 0.37165888116868867, mean accuracy: 0.86952, elapsed_time :215.40880370140076\n",
      "epoch: 44, mean loss: 0.3601176491402604, mean accuracy: 0.87168, elapsed_time :220.12967991828918\n",
      "epoch: 45, mean loss: 0.359179498861208, mean accuracy: 0.8746, elapsed_time :224.83654141426086\n",
      "epoch: 46, mean loss: 0.35748397735188076, mean accuracy: 0.875, elapsed_time :229.63477492332458\n",
      "epoch: 47, mean loss: 0.3483796627320292, mean accuracy: 0.87674, elapsed_time :234.27062392234802\n",
      "epoch: 48, mean loss: 0.34514898162744845, mean accuracy: 0.88038, elapsed_time :238.817045211792\n",
      "epoch: 49, mean loss: 0.34253520185075453, mean accuracy: 0.87898, elapsed_time :243.46234512329102\n",
      "epoch: 50, mean loss: 0.3382061346507896, mean accuracy: 0.88106, elapsed_time :248.07693099975586\n",
      "test accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "# オプティマイザの設定\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "student.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, NUM_EPOCH+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y_s = student(image)\n",
    "        \n",
    "        # 損失の計算\n",
    "        loss = F.cross_entropy(y_s, label)\n",
    "        \n",
    "        student.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y_s, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(f\"epoch: {epoch}, mean loss: {sum_loss/len(train_loader)}, mean accuracy: {count.item()/len(train_loader.dataset)}, elapsed_time :{time()-start}\")\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "student.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = student(image)\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studentネットワークの学習（DMLありの場合）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studentネットワークの用意\n",
    "今回はStudent 1と2を同じサイズのネットワークにしてDMLを実行します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student_1 を用意\n",
    "student_1 = CNN(widen_factor=1).cuda()\n",
    "# Student_2 を用意\n",
    "student_2 = CNN(widen_factor=1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL divergence lossの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_divergence(logits_1, logits_2):\n",
    "    softmax_1 = F.softmax(logits_1, dim=1)\n",
    "    softmax_2 = F.softmax(logits_2, dim=1)\n",
    "    kl = (softmax_2 * torch.log((softmax_2 / (softmax_1+1e-10)) + 1e-10)).sum(dim=1)\n",
    "    return kl.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習 & 評価\n",
    "2つのStudentネットワークを同時に学習させます．今回は，2つのネットワークの構造が同じであるため，student_1 の損失値と精度のみを表示します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mean loss: 1.7636436315448694, mean accuracy: 0.38394, elapsed_time :9.101534843444824\n",
      "epoch: 2, mean loss: 1.4273909632202304, mean accuracy: 0.52496, elapsed_time :18.395700216293335\n",
      "epoch: 3, mean loss: 1.2838651734544797, mean accuracy: 0.59446, elapsed_time :27.50475263595581\n",
      "epoch: 4, mean loss: 1.1773993244104068, mean accuracy: 0.64106, elapsed_time :36.766154289245605\n",
      "epoch: 5, mean loss: 1.1072002978580993, mean accuracy: 0.6705, elapsed_time :45.946645736694336\n",
      "epoch: 6, mean loss: 1.0481646541896683, mean accuracy: 0.69628, elapsed_time :55.16236162185669\n",
      "epoch: 7, mean loss: 1.0067015716334438, mean accuracy: 0.71352, elapsed_time :64.33563017845154\n",
      "epoch: 8, mean loss: 0.9621552775430557, mean accuracy: 0.73054, elapsed_time :73.71124601364136\n",
      "epoch: 9, mean loss: 0.9291094328893725, mean accuracy: 0.7448, elapsed_time :82.90313339233398\n",
      "epoch: 10, mean loss: 0.902424829314127, mean accuracy: 0.75474, elapsed_time :92.31488800048828\n",
      "epoch: 11, mean loss: 0.8795736546406661, mean accuracy: 0.7652, elapsed_time :101.59774279594421\n",
      "epoch: 12, mean loss: 0.8567832508660338, mean accuracy: 0.77586, elapsed_time :110.85142850875854\n",
      "epoch: 13, mean loss: 0.8404883814742193, mean accuracy: 0.78462, elapsed_time :120.22277355194092\n",
      "epoch: 14, mean loss: 0.8280625860480701, mean accuracy: 0.78808, elapsed_time :129.35638165473938\n",
      "epoch: 15, mean loss: 0.8048088571147236, mean accuracy: 0.79658, elapsed_time :138.59117650985718\n",
      "epoch: 16, mean loss: 0.7861148077813561, mean accuracy: 0.80384, elapsed_time :147.66780853271484\n",
      "epoch: 17, mean loss: 0.7701187711923628, mean accuracy: 0.81018, elapsed_time :156.47521090507507\n",
      "epoch: 18, mean loss: 0.7629122822104818, mean accuracy: 0.8146, elapsed_time :165.14477610588074\n",
      "epoch: 19, mean loss: 0.7477692472355445, mean accuracy: 0.81934, elapsed_time :173.73022603988647\n",
      "epoch: 20, mean loss: 0.7401975237804911, mean accuracy: 0.82402, elapsed_time :182.49897408485413\n",
      "epoch: 21, mean loss: 0.730771946175324, mean accuracy: 0.82974, elapsed_time :191.35705018043518\n",
      "epoch: 22, mean loss: 0.7181312296625293, mean accuracy: 0.83454, elapsed_time :200.00974106788635\n",
      "epoch: 23, mean loss: 0.7094781394962155, mean accuracy: 0.83834, elapsed_time :208.75378251075745\n",
      "epoch: 24, mean loss: 0.7036162989066385, mean accuracy: 0.84148, elapsed_time :217.60025882720947\n",
      "epoch: 25, mean loss: 0.6925513220336431, mean accuracy: 0.84566, elapsed_time :226.22238302230835\n",
      "epoch: 26, mean loss: 0.6858884792803498, mean accuracy: 0.84822, elapsed_time :234.93989324569702\n",
      "epoch: 27, mean loss: 0.6798455403817584, mean accuracy: 0.85108, elapsed_time :243.61500191688538\n",
      "epoch: 28, mean loss: 0.6674557308406781, mean accuracy: 0.85644, elapsed_time :252.49451780319214\n",
      "epoch: 29, mean loss: 0.6616824326460319, mean accuracy: 0.86154, elapsed_time :261.2515046596527\n",
      "epoch: 30, mean loss: 0.6546182100425291, mean accuracy: 0.86512, elapsed_time :270.0429825782776\n",
      "epoch: 31, mean loss: 0.6568849994169782, mean accuracy: 0.86424, elapsed_time :278.86166620254517\n",
      "epoch: 32, mean loss: 0.6473787260406157, mean accuracy: 0.86728, elapsed_time :287.57719707489014\n",
      "epoch: 33, mean loss: 0.6398654095352153, mean accuracy: 0.87246, elapsed_time :296.0393853187561\n",
      "epoch: 34, mean loss: 0.6351311013597967, mean accuracy: 0.87416, elapsed_time :304.78945875167847\n",
      "epoch: 35, mean loss: 0.6313739192607762, mean accuracy: 0.87776, elapsed_time :313.4637701511383\n",
      "epoch: 36, mean loss: 0.6240093057875133, mean accuracy: 0.88008, elapsed_time :322.1568431854248\n",
      "epoch: 37, mean loss: 0.6153549877426508, mean accuracy: 0.88376, elapsed_time :330.69905281066895\n",
      "epoch: 38, mean loss: 0.6178222954501886, mean accuracy: 0.88548, elapsed_time :339.11579942703247\n",
      "epoch: 39, mean loss: 0.6081885719657554, mean accuracy: 0.8855, elapsed_time :347.88085532188416\n",
      "epoch: 40, mean loss: 0.6080737471809168, mean accuracy: 0.88758, elapsed_time :356.669908285141\n",
      "epoch: 41, mean loss: 0.5986497152949233, mean accuracy: 0.8903, elapsed_time :365.42664551734924\n",
      "epoch: 42, mean loss: 0.5904611075092154, mean accuracy: 0.89464, elapsed_time :374.2436225414276\n",
      "epoch: 43, mean loss: 0.5889563696921024, mean accuracy: 0.89538, elapsed_time :383.05286622047424\n",
      "epoch: 44, mean loss: 0.5872364317059822, mean accuracy: 0.89592, elapsed_time :391.8808124065399\n",
      "epoch: 45, mean loss: 0.5894942216937195, mean accuracy: 0.89862, elapsed_time :400.64830136299133\n",
      "epoch: 46, mean loss: 0.5730578185957106, mean accuracy: 0.90294, elapsed_time :409.25721287727356\n",
      "epoch: 47, mean loss: 0.5750639560963492, mean accuracy: 0.90058, elapsed_time :418.0511677265167\n",
      "epoch: 48, mean loss: 0.5712238755982245, mean accuracy: 0.9027, elapsed_time :426.51024317741394\n",
      "epoch: 49, mean loss: 0.5686236328785986, mean accuracy: 0.9056, elapsed_time :434.8915340900421\n",
      "epoch: 50, mean loss: 0.5624736315377837, mean accuracy: 0.90864, elapsed_time :443.706827878952\n",
      "test accuracy: 0.8043\n"
     ]
    }
   ],
   "source": [
    "# オプティマイザの設定\n",
    "optimizer_1 = torch.optim.SGD(student_1.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer_2 = torch.optim.SGD(student_2.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# studentネットワークを学習モードへ変更\n",
    "student_1.train()\n",
    "student_2.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, NUM_EPOCH+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        # Student 1，２に画像を入力\n",
    "        y_1 = student_1(image)\n",
    "        y_2 = student_2(image)\n",
    "        \n",
    "        # Student 1の損失を計算 ＆ backprop\n",
    "        loss_1 = F.cross_entropy(y_1, label) + kl_divergence(y_1, y_2.detach())\n",
    "        student_1.zero_grad()\n",
    "        loss_1.backward()\n",
    "        # Student 1を更新\n",
    "        optimizer_1.step()\n",
    "        \n",
    "        # 更新後のStudent 1に再び画像を入力\n",
    "        y_1 = student_1(image)\n",
    "        \n",
    "        # Student 2の損失を計算 ＆ backprop\n",
    "        loss_2 = F.cross_entropy(y_2, label) + kl_divergence(y_2, y_1.detach())\n",
    "        student_2.zero_grad()\n",
    "        loss_2.backward()\n",
    "        # Student 2を更新\n",
    "        optimizer_2.step()\n",
    "        \n",
    "        sum_loss += loss_1.item()\n",
    "        \n",
    "        pred = torch.argmax(y_1, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(f\"epoch: {epoch}, mean loss: {sum_loss/len(train_loader)}, mean accuracy: {count.item()/len(train_loader.dataset)}, elapsed_time :{time()-start}\")\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "student_1.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = student_1(image)\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アンサンブルした際のテスト精度\n",
    "上記の結果は，学習したstudent_1とstudent_2のうち，student_1の損失値や精度を表示していました．\n",
    "DMLでは，最終的に2つの学習済みネットワークができるため，それらのネットワークのアンサンブル推論を計算することが可能です．\n",
    "ネットワークのアンサンブル推論とは，以下のように各ネットワークの出力の平均値を最終的な推論結果とするものです．\n",
    "\n",
    "$$\n",
    "p^{ens}(x) = \\frac{1}{K} \\sum^K_k {p^{\\theta_k}(x)}\n",
    "$$\n",
    "\n",
    "このように，複数の学習済みネットワークの予測を組み合わせることで，推論時の精度を向上させることができます．\n",
    "\n",
    "以下のコードは，2つのネットワークをアンサンブルした際のテスト精度を求めるものです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8215\n"
     ]
    }
   ],
   "source": [
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y_1 = student_1(image)\n",
    "        y_2 = student_2(image)\n",
    "        \n",
    "        # student_1 と student_2 の予測結果の平均を計算\n",
    "        y = (y_1 + y_2) / 2\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "上記のプログラムは，2つのStudentネットワークが全く同じ構造になっていました．\n",
    "Student 2 のネットワークサイズを変更するとStudent 1 のネットワークの精度がどう変化するのかを調べてください．（CNNクラスの引数であるwiden_factorを変更するとネットワークサイズを変えることができます．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Knowledge distillation\n",
    "\n",
    "DNNは一般的に，ネットワークのパラメータ数を増やす（層の数やチャネル数を増やす）と性能が向上していきます．しかし，ネットワークのパラメータ数を増やすと，それに伴って，実行時に必要なメモリ量や計算コストが増えてしまいます．実応用上，少ないメモリ量と計算コストで高性能な推論ができる小さなネットワークを作ることが望まれます．\n",
    "\n",
    "Knowledge distillation（知識蒸留）は，そのような小さくて高性能なネットワークを作るための学習方法です．これには，TeacherネットワークとStudentネットワークと呼ばれる2つのネットワークを使用します．以下に，クラス分類問題を解くネットワークにおけるknowledge distillationの学習方法を示します．\n",
    "\n",
    "<img src=\"https://paper-attachments.dropbox.com/s_87B2D47FBD0A698415C3853F712E17ACC67F633356B04D1BA9138A68175CE0AD_1596688289510_image.png\" width = 40%>\n",
    "\n",
    "Teacherネットワークは大きくて優秀な事前学習済み(pre-trained)ネットワークであり，StudentネットワークはTeacherネットワークよりも小さなネットワークです．事前学習済みのTeacherネットワークが持っている知識を，Teacherネットワークに教えながら学習させることで，Studentネットワークの性能が向上します．通常の学習では，ネットワークの推論結果が，人間が作成した正解ラベル(Hard target)と一致するように学習を行います．Knowledge distillationでは，Hard targetに加えて，Teacherネットワークの出力(Soft target)にも一致するようにStudentネットワークを学習させます．損失関数はどちらもクロスエントロピー関数を使用します．このように学習することで，distillationを用いない場合よりもStudentネットワークの性能が向上します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## なぜ性能が向上するのか？\n",
    "\n",
    "クラス分類問題を解くネットワークを教師あり学習で学習させる場合，教師ラベル(Hard target)として正解クラスのみが1で他のクラスが0になっているデータを使用します．例えば，正解クラスがdogである場合には，以下の図ようにdogクラスのみが1になっており，それ以外のcatやcow, carなどのクラスは0になっている配列 [0, 1, 0, 0, …] を教師ラベルとして使用します．\n",
    "\n",
    "<img src=\"https://paper-attachments.dropbox.com/s_87B2D47FBD0A698415C3853F712E17ACC67F633356B04D1BA9138A68175CE0AD_1596368489677_image.png\" width = 30%>\n",
    "\n",
    "これに対して，学習済みのTeacherネットワークが出力する値(Soft target)は，以下の図のように，dogクラス以外にも0より大きな値が存在します．一般的に，この値は正解クラスと見た目が近いほど大きく，遠いほど小さくなります．この例では，dogクラスと見た目が近いcatクラスが2番目に大きな値を持っており，大きく見た目の異なるcarクラスは非常に小さな値となっています．\n",
    "\n",
    "<img src=\"https://paper-attachments.dropbox.com/s_87B2D47FBD0A698415C3853F712E17ACC67F633356B04D1BA9138A68175CE0AD_1596368473731_image.png\" width = 30%>\n",
    "\n",
    "つまり，学習済みのネットワークが出力する値には，入力画像に対する正解クラスの類似度情報（ここではdogクラスの0.9）の他に，正解クラス”以外”の類似度情報も含まれています．優秀なTeacherネットワークから得られた，この類似度情報をStudentネットワークに伝えることで，Studentネットワークの精度が向上すると考えられています．（※ただし，理論的な証明はまだ存在していません．また，この他にも”ラベル平滑化”による正則化の効果など，複数の要因によって性能が向上すると考えられています．）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習方法\n",
    "\n",
    "KDでは以下の2段階の手順でネットワークを学習します．\n",
    "\n",
    "1. 教師ラベル(hard target)を使ってTeacherネットワークを学習させる\n",
    "2. 教師ラベル(hard target)と学習済みのTeacherネットワークの出力(soft target)を使ってStudentネットワークを学習させる\n",
    "\n",
    "#### ステップ 1\n",
    "Teacherネットワークの学習は通常の教師あり学習です．損失関数として，教師ラベルとのCross entropy lossを使用します．このとき，学習させたTeacherネットワークを保存しておき，次のステップで使います．\n",
    "\n",
    "#### ステップ 2\n",
    "Studentネットワークの学習では，教師ラベルを使用した通常の教師あり学習に加え，学習済みTeacherネットワークの出力を模倣するような学習を行います．\n",
    "\n",
    "教師ラベル(hard target)との損失を計算する際にはcross entropy lossを使用します．損失関数は以下のように表されます．\n",
    "\n",
    "$$L_{hard} = - \\sum^C_i{t_i \\log{p^s_i(x)}}$$\n",
    "\n",
    "ここで，$C$はクラス数，$t_i \\in \\{0,1\\}$は$i$番目クラスの教師ラベル値，$x$は入力画像，$p^s_i$はStudentネットワークの出力をsoftmax関数で正規化した後の，$i$番目クラスの確率値です (例えば，dogクラスの0.9や，catクラスの0.1などです)．この損失関数は，通常の教師あり学習で使用するものとまったく同じ関数です．\n",
    "\n",
    "Teacherネットワークの出力(soft target)との損失を計算する際にも同様にcross entropy lossを使用します．損失関数は以下のように表されます．これがdistillationに使われる損失関数です．\n",
    "\n",
    "$$L_{soft} = - \\sum^C_i{p^t_i(x; \\tau) \\log{p^s_i(x; \\tau)}}$$\n",
    "\n",
    "ここで，$p^t_i$はTeacherネットワークの出力をsoftmax関数で正規化した後の，$i$番目クラスの確率値です．また，$\\tau$は温度パラメータと呼ばれるもので，softmax関数によって正規化された確率分布の滑らかさを決定する値です．この温度付きsoftmax関数には，Teacherネットワークの情報をStudentネットワークに伝えやすくする役割があります．\n",
    "\n",
    "最終的な損失は以下のように計算します．$\\alpha$は蒸留用の損失をどれだけ考慮するかを決定するパラメータです．\n",
    "$$L = L_{hard} + \\alpha \\cdot L_{soft}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax関数の温度パラメータ\n",
    "\n",
    "温度付きSoftmax関数とは，以下の式で表される関数です．ここで，$z$がネットワークの出力(logits)，$\\tau$が温度パラメータを表します．温度$\\tau$を高い値にすることで，正規化後の確率分布が滑らかになります．\n",
    "\n",
    "$$p_i = \\frac{exp(z_i/\\tau)}{\\sum^C_k{exp(z_k/\\tau)}}$$\n",
    "\n",
    "温度付きSoftmax関数の振る舞いを理解するため，以下に温度$\\tau$を変更した際の，各クラスの確率値$p_i$の分布を示します．左がネットワークの出力$z_i$の分布，中央が$\\tau=1$で$z_i$を正規化したときの確率$p_i$の分布，右が$\\tau=4$の場合の確率$p_i$の分布です．温度を上げることで確率分布が変化していることが分かります．(プログラム中の”T”の値を書き換えて，分布がどのように変化するか調べてみてください)\n",
    "\n",
    "通常のsoftmax関数($\\tau=1$の場合に相当)は，最も大きな値のみが1に近く，それ以外は0に近い値となります．この状態のままクロスエントロピー関数を使って蒸留すると，Teacherネットワークが持つ不正解クラスの情報がStudentネットワークにうまく伝わりません．温度パラメータを導入し，$\\tau$の値を大きくすることで，不正解クラスの確率値がある程度大きくなるため，その情報が伝わりやすくなります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_name = [\"car\",\"cat\", \"deer\", \"dog\", \"cow\"]\n",
    "z = torch.tensor([-5.2, 6.3, -0.5, 9.4, 3.1])\n",
    "\n",
    "T = 1\n",
    "p_1 = torch.softmax(z/T, dim=0)\n",
    "\n",
    "T = 4\n",
    "p_4 = torch.softmax(z/T, dim=0)\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(18,4))\n",
    "ax1.bar(class_name, z)\n",
    "ax2.bar(class_name, p_1)\n",
    "ax3.bar(class_name, p_4)\n",
    "ax2.set_ylim([0,1])\n",
    "ax3.set_ylim([0,1])\n",
    "ax1.set_title(\"$z_i$: logits\")\n",
    "ax2.set_title(\"$p_i$: softmax (T=1)\")\n",
    "ax3.set_title(\"$p_i$: softmax (T=4)\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みニューラルネットワークのknowledge distillation\n",
    "クラス分類問題を解くネットワークに対して，knowledge distillationを適用した学習を行います．\n",
    "データセットには一般物体認識用のデータセットであるCIFAR-10を使います．CIFAR-10は10クラスの画像からなるデータセットです．\n",
    "蒸留では，\n",
    "\n",
    "1. Teacherネットワークを学習させる\n",
    "2. Studentネットワークを学習させる\n",
    "\n",
    "という2段階の学習を行います．\n",
    "この実験の目的は，Studentネットワークの精度が，蒸留を使用しない通常の学習よりも向上するかどうかを確かめることです．\n",
    "そのため，Studentネットワークを蒸留を用いずに学習させた場合と，蒸留を用いて学習させた場合の2つを比較します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# エポック数の設定\n",
    "NUM_EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# データローダーの準備\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"./dataset/CIFAR-10\", train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"./dataset/CIFAR-10\", train=False, transform=test_transform, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=10)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=100, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ネットワークの用意\n",
    "畳み込みネットワークを定義します．ここでは，2層の畳み込み層と3層の全結合層により構成されるネットワークとします．\n",
    "widen_factorという引数は，畳み込み層のフィルタ数と全結合層のユニット数をデフォルトの値から何倍するかを決定するものです．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, widen_factor=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16*widen_factor, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16*widen_factor, 32*widen_factor, kernel_size=3, stride=1, padding=1)\n",
    "        self.l1 = nn.Linear(8*8*32*widen_factor, 1024*widen_factor)\n",
    "        self.l2 = nn.Linear(1024*widen_factor, 1024*widen_factor)\n",
    "        self.l3 = nn.Linear(1024*widen_factor, 10)\n",
    "        self.act = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = self.pool(self.act(self.conv1(x)))\n",
    "        h = self.pool(self.act(self.conv2(h)))\n",
    "        h = h.view(h.size()[0], -1)\n",
    "        h = self.act(self.l1(h))\n",
    "        h = self.act(self.l2(h))\n",
    "        h = self.l3(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teacherネットワークの学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacherネットワークの用意\n",
    "Teacherネットワークを作成します．今回は，widen_factor=2 の大きなネットワークを用意します．\n",
    "サマリーの Total params を見ると，パラメータ数が 12,626,890 あることが分かります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 32, 32]             896\n",
      "              ReLU-2           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-3           [-1, 32, 16, 16]               0\n",
      "            Conv2d-4           [-1, 64, 16, 16]          18,496\n",
      "              ReLU-5           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-6             [-1, 64, 8, 8]               0\n",
      "            Linear-7                 [-1, 2048]       8,390,656\n",
      "              ReLU-8                 [-1, 2048]               0\n",
      "            Linear-9                 [-1, 2048]       4,196,352\n",
      "             ReLU-10                 [-1, 2048]               0\n",
      "           Linear-11                   [-1, 10]          20,490\n",
      "================================================================\n",
      "Total params: 12,626,890\n",
      "Trainable params: 12,626,890\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.91\n",
      "Params size (MB): 48.17\n",
      "Estimated Total Size (MB): 49.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# teacher を用意\n",
    "teacher = CNN(widen_factor=2).cuda()\n",
    "# teacher のサマリーを表示\n",
    "torchsummary.summary(model=teacher, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習 & 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, mean loss: 1.907318680049181, mean accuracy: 0.29028, elapsed_time :92.82638454437256\n",
      "epoch: 2, mean loss: 1.816010889685154, mean accuracy: 0.34434, elapsed_time :186.4812033176422\n",
      "epoch: 3, mean loss: 1.8127907244163752, mean accuracy: 0.35192, elapsed_time :279.5665032863617\n",
      "epoch: 4, mean loss: 1.8259026667112113, mean accuracy: 0.34108, elapsed_time :375.3521873950958\n",
      "epoch: 5, mean loss: 1.8619633865261078, mean accuracy: 0.3288, elapsed_time :468.97943115234375\n",
      "epoch: 6, mean loss: 1.870491851181984, mean accuracy: 0.32162, elapsed_time :562.7674753665924\n",
      "epoch: 7, mean loss: 1.8735470607209206, mean accuracy: 0.32242, elapsed_time :658.047901391983\n",
      "epoch: 8, mean loss: 1.88550818618536, mean accuracy: 0.31964, elapsed_time :751.8262195587158\n",
      "epoch: 9, mean loss: 1.895700322008133, mean accuracy: 0.3117, elapsed_time :844.2108945846558\n",
      "epoch: 10, mean loss: 1.9028598303961755, mean accuracy: 0.30848, elapsed_time :938.1039531230927\n",
      "epoch: 11, mean loss: 1.8935062318277358, mean accuracy: 0.31242, elapsed_time :1032.061677455902\n",
      "epoch: 12, mean loss: 1.910229567246437, mean accuracy: 0.30434, elapsed_time :1125.3778522014618\n",
      "epoch: 13, mean loss: 1.9083600441503525, mean accuracy: 0.30314, elapsed_time :1219.512443304062\n",
      "epoch: 14, mean loss: 1.9359507335662842, mean accuracy: 0.29228, elapsed_time :1313.0454652309418\n",
      "epoch: 15, mean loss: 1.9331421252584458, mean accuracy: 0.29106, elapsed_time :1406.295385837555\n",
      "epoch: 16, mean loss: 1.92634939722538, mean accuracy: 0.29534, elapsed_time :1499.403685092926\n",
      "epoch: 17, mean loss: 1.9178845082139968, mean accuracy: 0.29686, elapsed_time :1595.3845188617706\n"
     ]
    }
   ],
   "source": [
    "# オプティマイザの設定\n",
    "optimizer = torch.optim.SGD(teacher.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "teacher.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, NUM_EPOCH+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = teacher(image)\n",
    "        \n",
    "        # 損失の計算\n",
    "        loss = F.cross_entropy(y, label)\n",
    "        \n",
    "        teacher.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(f\"epoch: {epoch}, mean loss: {sum_loss/len(train_loader)}, mean accuracy: {count.item()/len(train_loader.dataset)}, elapsed_time :{time()-start}\")\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "teacher.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = teacher(image)\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの保存\n",
    "学習済みのTeacherネットワークの重みパラメータを保存しておきます．こうすることで，再実験を行う際に，Teacherネットワークを再度学習させなくても済むようになります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(teacher, \"teacher.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studentネットワーク単体の学習（KDなしの場合）\n",
    "後で比較をするために，Studentネットワークに対して，knowledge distillationを適用しない通常の学習を行います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studentネットワークの用意\n",
    "Studentネットワークを作成します．Teacherネットワークよりも小さなネットワークにするため widen_factor=1 にします．Teacherネットワークのパラメータ数は 12,626,890 でしたが，Studentネットワークのパラメータ数は 3,163,114 であり，約4分の1になっていることが分かります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# student を用意\n",
    "student = CNN(widen_factor=1).cuda()\n",
    "# teacher のサマリーを表示\n",
    "torchsummary.summary(model=student, input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習 & 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプティマイザの設定\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ネットワークを学習モードへ変更\n",
    "student.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, NUM_EPOCH+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y_s = student(image)\n",
    "        \n",
    "        # 損失の計算\n",
    "        loss = F.cross_entropy(y_s, label)\n",
    "        \n",
    "        student.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y_s, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(f\"epoch: {epoch}, mean loss: {sum_loss/len(train_loader)}, mean accuracy: {count.item()/len(train_loader.dataset)}, elapsed_time :{time()-start}\")\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "student.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = student(image)\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Studentネットワークの学習（KDありの場合）\n",
    "学習済みTeacherネットワークを使ってknowledge distillationを行います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacherネットワークの読み込み\n",
    "先ほど保存したTeacherネットワークの重みパラメータをteacherに読み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = torch.load(\"teacher.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Studentネットワークの用意\n",
    "Studentネットワークの重みを初期化するため，再度ネットワークを作成します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = CNN(widen_factor=1).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy lossの定義\n",
    "蒸留用の損失関数を定義します．StudentネットワークとTeacherネットワークの出力(logits)に対して温度付きsoftmaxで正規化し，cross entropy lossを計算します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(student_logits, teacher_logits, T):\n",
    "    student_log_softmax = F.log_softmax(student_logits/T, dim=1)\n",
    "    teacher_softmax = F.softmax(teacher_logits/T, dim=1)\n",
    "    ce = -(teacher_softmax * student_log_softmax).sum(dim=1)\n",
    "    return ce.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習 & 評価\n",
    "$L_{hard}$と$L_{soft}$の2つの損失関数を使用して，Studentネットワークを学習させます．\n",
    "今回は，温度パラメータを 4，$\\alpha$を 4 に設定します．\n",
    "Studentネットワークの損失値と精度を表示します．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプティマイザの設定\n",
    "optimizer = torch.optim.SGD(student.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# studentネットワークのみを学習モードへ変更\n",
    "teacher.eval()\n",
    "student.train()\n",
    "\n",
    "start = time()\n",
    "for epoch in range(1, NUM_EPOCH+1):\n",
    "    sum_loss = 0.0\n",
    "    count = 0\n",
    "    \n",
    "    for image, label in train_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        # Teacherネットワークの出力を得る\n",
    "        y_t = teacher(image)\n",
    "        # Studentネットワークの出力を得る\n",
    "        y_s = student(image)\n",
    "        \n",
    "        # 損失の計算\n",
    "        hard_loss = F.cross_entropy(y_s, label)\n",
    "        soft_loss = cross_entropy(y_s, y_t.detach(), T=4.)\n",
    "        loss = hard_loss + 4.0 * soft_loss\n",
    "        \n",
    "        student.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        sum_loss += loss.item()\n",
    "        \n",
    "        pred = torch.argmax(y_s, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "        \n",
    "    print(f\"epoch: {epoch}, mean loss: {sum_loss/len(train_loader)}, mean accuracy: {count.item()/len(train_loader.dataset)}, elapsed_time :{time()-start}\")\n",
    "\n",
    "# ネットワークを評価モードへ変更\n",
    "student.eval()\n",
    "\n",
    "# 評価の実行\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for image, label in test_loader:\n",
    "        \n",
    "        image = image.cuda()\n",
    "        label = label.cuda()\n",
    "        \n",
    "        y = student(image)\n",
    "        \n",
    "        pred = torch.argmax(y, dim=1)\n",
    "        count += torch.sum(pred == label)\n",
    "\n",
    "print(f\"test accuracy: {count.item()/len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 課題\n",
    "1. 温度パラメータ $\\tau$ の値や$\\alpha$の値を変更して精度の変化を調査してください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc-autonumbering": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

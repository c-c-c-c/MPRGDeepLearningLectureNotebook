{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/machine-perception-robotics-group/MPRGDeepLearningLectureNotebook/blob/master/13_rnn/05_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzuK1IkM_JLD"
   },
   "source": [
    "# Attention Seq2seq\n",
    "前セクションでは，Seq2seqについて学びました．本セクションでは，計算機がどの数字，演算記号に着目したかをAttention機構を導入することで調査します．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrHbUcaD_74x"
   },
   "source": [
    "# Attention機構\n",
    "Seq2Seqはエンコーダが長期のパターンを学習する際に直近の情報に強く影響されるため，過去の特徴をうまく捉えることが難しいとされています．そこで，各時刻のエンコーダの出力を保持し，デコーダ側へ情報を伝搬するAttention機構を導入することで，この問題を解決します．Attention機構は保持したエンコーダの出力をデコーダの出力に対して重みづけすることで，どの時刻のエンコーダに着目してデコーダが文字等の情報を生成したかを可視化することもできます．\n",
    "\n",
    "<img src=\"https://github.com/himidev/Lecture/blob/main/13_rnn/05_Attention/Atten_Seq2seq.png?raw=true\" width = 100%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBi4hC_uAJNM"
   },
   "source": [
    "###データローダの作成\n",
    "まず，データローダを用意します．データは0から9までの数字と加算記号，開始，終了のフラグです．また，３桁の数字の足し算を行うため，各桁の値を１つずつランダムに生成して連結しています．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rOgzz6W1CYU3"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "word2id = {str(i): i for i in range(10)}\n",
    "word2id.update({\"<pad>\": 10, \"+\": 11, \"<eos>\": 12})\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "class CalcDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def transform(self, string, seq_len=7):\n",
    "        tmp = []\n",
    "        for i, c in enumerate(string):\n",
    "            try:\n",
    "                tmp.append(word2id[c])\n",
    "            except:\n",
    "                tmp += [word2id[\"<pad>\"]] * (seq_len - i)\n",
    "                break\n",
    "        return tmp\n",
    "\n",
    "    def __init__(self, data_num, train=True):\n",
    "        super().__init__()\n",
    "        self.data_num = data_num\n",
    "        self.train = train\n",
    "        self.data = []\n",
    "        self.label = []\n",
    "\n",
    "        for _ in range(data_num):\n",
    "            x = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] ))\n",
    "            y = int(\"\".join([random.choice(list(\"0123456789\")) for _ in range(random.randint(1, 3))] ))\n",
    "            left = (\"{:*<7s}\".format(str(x) + \"+\" + str(y))).replace(\"*\", \"<pad>\")\n",
    "            self.data.append(self.transform(left))\n",
    "\n",
    "            z = x + y\n",
    "            right = (\"{:*<6s}\".format(str(z))).replace(\"*\", \"<pad>\")\n",
    "            right = self.transform(right, seq_len=5)\n",
    "            right = [12] + right\n",
    "            right[right.index(10)] = 12\n",
    "            self.label.append(right)\n",
    "        \n",
    "\n",
    "\n",
    "        self.data = np.asarray(self.data)\n",
    "        self.label = np.asarray(self.label)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        d = self.data[item]\n",
    "        l = self.label[item]\n",
    "        return d, l\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVK7nlTvAO3v"
   },
   "source": [
    "###エンコーダ・デコーダの作成\n",
    "基本的な構造は前セクションのエンコーダ・デコーダ構造と同様です．ただし，エンコーダは各時刻の出力値を保持しておきます．デコーダでは，保持したエンコーダの出力値とデコーダの出力値で内積計算します．この内積計算によって，各時刻のエンコーダの出力値に重み付けすることができます．これにより，どの時刻のエンコーダの出力に着目したかをデコーダ側が自動で決定することができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "O3u7W6gmC1gC",
    "outputId": "1bada41c-e768-4c2b-e79f-f90450aef0af"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-88c195419edc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_weights_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# Flattens params (on CUDA)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mflatten_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cudnn_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproj_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                         self.batch_first, bool(self.bidirectional))  # type: ignore\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "embedding_dim = 16\n",
    "hidden_dim = 128\n",
    "vocab_size = len(word2id)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=30):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "    def forward(self, indices):\n",
    "        embedding = self.word_embeddings(indices)\n",
    "        if embedding.dim() == 2:\n",
    "            embedding = torch.unsqueeze(embedding, 1)\n",
    "        hs, state = self.gru(embedding, torch.zeros(1, self.batch_size, self.hidden_dim, device=device))\n",
    "\n",
    "        return hs, state\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, batch_size=100):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=word2id[\"<pad>\"])\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.output = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, index, hs, state):\n",
    "        embedding = self.word_embeddings(index)\n",
    "        if embedding.dim() == 2:\n",
    "            embedding = torch.unsqueeze(embedding, 1)\n",
    "        gruout, state = self.gru(embedding, state)\n",
    "\n",
    "        t_output = torch.transpose(gruout, 1, 2)\n",
    "        s = torch.bmm(hs, t_output)\n",
    "        attention_weight = self.softmax(s)\n",
    "\n",
    "        c = torch.zeros(self.batch_size, 1, self.hidden_dim, device=device)\n",
    "\n",
    "        # attention weight\n",
    "        for i in range(attention_weight.size()[2]):\n",
    "          unsq_weight = attention_weight[:,:,i].unsqueeze(2)\n",
    "          weighted_hs = hs * unsq_weight\n",
    "          weight_sum = torch.sum(weighted_hs, axis=1).unsqueeze(1)\n",
    "          c = torch.cat([c, weight_sum], dim=1)\n",
    "        c = c[:,1:,:]\n",
    "        gruout = torch.cat([gruout, c], dim=2)\n",
    "        output = self.output(gruout)\n",
    "        return output, state, attention_weight\n",
    "\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=100).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=100).to(device)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2id[\"<pad>\"])\n",
    "\n",
    "# Initialize opotimizers\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.001)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpqiPRtXBvCa"
   },
   "source": [
    "###学習\n",
    "前セクション同様の条件で学習を行います．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T__Mg3C8C4dQ",
    "outputId": "ebd412d3-0c23-40bb-aac8-c01eae8e2056"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "# GPUの確認\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print('Use CUDA:', use_cuda)\n",
    "\n",
    "batch_size=100\n",
    "epoch_num = 200\n",
    "\n",
    "train_data = CalcDataset(data_num = 20000)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "all_losses = []\n",
    "start = time()\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    epoch_loss = 0\n",
    "    for data, label in train_loader:\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "            label = label.cuda()\n",
    "\n",
    "        hs, encoder_hidden = encoder(data)\n",
    "        source = label[:, :-1]\n",
    "        target = label[:, 1:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "\n",
    "        loss = 0\n",
    "        decoder_output, _, attention_weight = decoder(source, hs, decoder_hidden)\n",
    "        decoder_output = torch.squeeze(decoder_output)\n",
    "        for j in range(decoder_output.size()[1]):\n",
    "            loss += criterion(decoder_output[:, j, :], target[:, j])\n",
    "        #for i in range(source.size(1)):\n",
    "        #    decoder_output, decoder_hidden = decoder(source[:, i], hs, decoder_hidden)\n",
    "        #    decoder_output = torch.squeeze(decoder_output)\n",
    "        #    loss += criterion(decoder_output, target[:, i])\n",
    "\n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Adjust model weights\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "  \n",
    "    elapsed_time = time() - start\n",
    "    all_losses.append(epoch_loss)\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"epoch: {}, mean loss: {}, elapsed_time: {}\".format(epoch, loss.item(), elapsed_time))\n",
    "        \n",
    "model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
    "torch.save({\n",
    "    'encoder_model': encoder.state_dict(),\n",
    "    'decoder_model': decoder.state_dict(),\n",
    "}, model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bax8En0jB0d0"
   },
   "source": [
    "###評価\n",
    "こちらも前セクション同様に学習モデルを評価します．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWZHuSwcC6nj",
    "outputId": "a3e5ac8a-4e56-4039-ad1e-dc2bba951701"
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "test_data = CalcDataset(data_num = 2000)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
    "\n",
    "model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
    "checkpoint = torch.load(model_name)\n",
    "encoder.load_state_dict(checkpoint[\"encoder_model\"])\n",
    "decoder.load_state_dict(checkpoint[\"decoder_model\"])\n",
    "\n",
    "accuracy = 0\n",
    "        \n",
    "# 評価の実行   \n",
    "with torch.no_grad():\n",
    "    for data, label in test_loader:\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "\n",
    "        hs, state = encoder(data)\n",
    "\n",
    "        right = []\n",
    "        token = \"<eos>\"\n",
    "        for _ in range(7):\n",
    "            index = word2id[token]\n",
    "            input_tensor = torch.tensor([index], device=device)\n",
    "            output, state, _ = decoder(input_tensor, hs, state)\n",
    "            prob = F.softmax(torch.squeeze(output))\n",
    "            index = torch.argmax(prob.cpu().detach()).item()\n",
    "            token = id2word[index]\n",
    "            if token == \"<eos>\":\n",
    "                break\n",
    "            right.append(token)\n",
    "        right = \"\".join(right)\n",
    "        \n",
    "        x = list(data[0].to('cpu').detach().numpy() )\n",
    "        try:\n",
    "            padded_idx_x = x.index(word2id[\"<pad>\"])\n",
    "        except ValueError:\n",
    "            padded_idx_x = len(x)\n",
    "        left = \"\".join(map(lambda c: str(id2word[c]), x[:padded_idx_x]))\n",
    "\n",
    "        flag = [\"F\", \"T\"][eval(left) == int(right)]\n",
    "        print(\"{:>7s} = {:>4s} :{}\".format(left, right, flag))\n",
    "        if flag == \"T\":\n",
    "            accuracy += 1\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy / len(test_loader)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IABUmPziCte"
   },
   "source": [
    "# Attentionの可視化\n",
    "Decoder内のAttention weightの可視化をします．Attention weightを見ることで，デコーダがどのエンコーダの入力に着目したかを確認することができます．Attention　weightの可視化にはヒートマップがよく用いられるので，ヒートマップで可視化してみます．ただし，全ての評価サンプルを確認すると時間もかかるので，今回は5サンプルを実行するごとにランダム表示します．ヒートマップは縦軸がエンコーダの入力，横軸がデコーダの出力を表しています．１数字ずつ見たとき、左に並んでいるボックスの色が一番明るいところの文字が最も着目して生成された数値を表しています．プロット毎に数値をランダムにしているので，各自ヒートマップの結果を考察してみてください．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "et3OwgNlQdsg",
    "outputId": "11749e5e-0950-408b-caf0-69e1dca64a27"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "batch_size = 1\n",
    "test_data = CalcDataset(data_num = 2000)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "encoder = Encoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
    "decoder = Decoder(vocab_size, embedding_dim, hidden_dim, batch_size=1).to(device)\n",
    "\n",
    "model_name = \"seq2seq_calculator_v{}.pt\".format(epoch)\n",
    "checkpoint = torch.load(model_name)\n",
    "encoder.load_state_dict(checkpoint[\"encoder_model\"])\n",
    "decoder.load_state_dict(checkpoint[\"decoder_model\"])\n",
    "\n",
    "accuracy = 0\n",
    "        \n",
    "# 評価の実行   \n",
    "with torch.no_grad():\n",
    "    for ind, (data, label) in enumerate(test_loader):\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "\n",
    "        hs, state = encoder(data)\n",
    "\n",
    "        right = []\n",
    "        Atten = []\n",
    "        token = \"<eos>\"\n",
    "        for _ in range(7):\n",
    "            index = word2id[token]\n",
    "            input_tensor = torch.tensor([index], device=device)\n",
    "            output, state, attention_weight = decoder(input_tensor, hs, state)\n",
    "            prob = F.softmax(torch.squeeze(output))\n",
    "            index = torch.argmax(prob.cpu().detach()).item()\n",
    "            token = id2word[index]\n",
    "            if token == \"<eos>\":\n",
    "                break\n",
    "            right.append(token)\n",
    "            Atten.append(attention_weight.cpu().detach().numpy())\n",
    "        str_right = right\n",
    "        right = \"\".join(right)\n",
    "        \n",
    "        x = list(data[0].to('cpu').detach().numpy() )\n",
    "        try:\n",
    "            padded_idx_x = x.index(word2id[\"<pad>\"])\n",
    "        except ValueError:\n",
    "            padded_idx_x = len(x)\n",
    "        left = \"\".join(map(lambda c: str(id2word[c]), x[:padded_idx_x]))\n",
    "        str_left = []\n",
    "        for s in range(len(x)):\n",
    "          if str(x[s]) == '11':\n",
    "            str_left.append('+')\n",
    "          elif str(x[s]) == '10':\n",
    "            str_left.append('=')\n",
    "          else:\n",
    "            str_left.append(str(x[s]))\n",
    "\n",
    "        flag = [\"F\", \"T\"][eval(left) == int(right)]\n",
    "        print(\"{:>7s} = {:>4s} :{}\".format(left, right, flag))\n",
    "        Atten = np.concatenate(Atten, axis=0)\n",
    "        Atten = Atten[:, :, 0].transpose(1, 0)\n",
    "        df = pd.DataFrame(Atten, index=str_left, columns=str_right)\n",
    "        plt.figure(figsize=[12, 8])\n",
    "        sns.heatmap(df)\n",
    "        if ind == 4:\n",
    "          sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJeoXisaCnok"
   },
   "source": [
    "# 課題\n",
    "* 四則演算を変えてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxtXQWzDCuSf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNfKKHcqVctFIbUysOfjEJA",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "05_Attention.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
